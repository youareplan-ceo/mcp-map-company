#!/bin/bash
# scripts/ci_error_analyzer.sh
#
# CI/CD ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ ë° ì•Œë¦¼ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
#
# ì£¼ìš” ê¸°ëŠ¥:
# - ìµœê·¼ 7ì¼ê°„ CI/CD ë¡œê·¸ ë¶„ì„
# - ì‹¤íŒ¨ ë¹Œë“œ/í…ŒìŠ¤íŠ¸ Top10 ì›ì¸ ì¶”ì¶œ
# - ë¡œê·¸ í¬ê¸° > 1MB íŒŒì¼ ìë™ ì••ì¶•
# - ì—ëŸ¬ ìœ í˜•ë³„ ë¹ˆë„ ì§‘ê³„ (ë¹Œë“œ, í…ŒìŠ¤íŠ¸, ë°°í¬)
# - Markdown/JSON ë¦¬í¬íŠ¸ ìƒì„±
# - ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™

set -euo pipefail

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸€ë¡œë²Œ ë³€ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
readonly SCRIPT_NAME="$(basename "$0")"
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# ê¸°ë³¸ ì„¤ì •
DAYS="${CI_ERROR_ANALYZER_DAYS:-7}"
OUTPUT_FORMAT="${CI_ERROR_ANALYZER_FORMAT:-text}"
DRY_RUN="${CI_ERROR_ANALYZER_DRY_RUN:-false}"
VERBOSE="${CI_ERROR_ANALYZER_VERBOSE:-false}"
OUTPUT_DIR="${CI_ERROR_ANALYZER_OUTPUT_DIR:-${PROJECT_ROOT}/logs/ci_errors}"
GITHUB_TOKEN="${GITHUB_TOKEN:-}"
COMPRESS_THRESHOLD="${CI_ERROR_ANALYZER_COMPRESS_MB:-1}"
ALERT_ENABLED="${CI_ERROR_ANALYZER_ALERT_ENABLED:-true}"

# ìƒ‰ìƒ ì •ì˜
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly PURPLE='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly WHITE='\033[1;37m'
readonly NC='\033[0m' # No Color

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê¹… ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log() {
    echo -e "${WHITE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $*" >&2
}

log_info() {
    echo -e "${BLUE}â„¹ï¸  [INFO]${NC} $*" >&2
}

log_warn() {
    echo -e "${YELLOW}âš ï¸  [WARN]${NC} $*" >&2
}

log_error() {
    echo -e "${RED}âŒ [ERROR]${NC} $*" >&2
}

log_success() {
    echo -e "${GREEN}âœ… [SUCCESS]${NC} $*" >&2
}

log_debug() {
    if [[ "$VERBOSE" == "true" ]]; then
        echo -e "${PURPLE}ğŸ” [DEBUG]${NC} $*" >&2
    fi
}

die() {
    log_error "$*"
    exit 1
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë„ì›€ë§ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
show_help() {
    cat << 'EOF'
ğŸš¨ MCP-MAP CI/CD ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ê¸°

ì‚¬ìš©ë²•:
    ./scripts/ci_error_analyzer.sh [ì˜µì…˜]

ì˜µì…˜:
    --days N                ë¶„ì„í•  ì¼ìˆ˜ (ê¸°ë³¸ê°’: 7)
    --format FORMAT         ì¶œë ¥ í˜•ì‹: text|json|markdown (ê¸°ë³¸ê°’: text)
    --output-dir DIR        ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: logs/ci_errors)
    --dry-run              ì‹¤ì œ ë³€ê²½ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ë§Œ ì‹¤í–‰
    --verbose              ìƒì„¸ ë¡œê·¸ ì¶œë ¥
    --no-alert             ì•Œë¦¼ ì „ì†¡ ë¹„í™œì„±í™”
    --compress-mb SIZE     ì••ì¶• ì„ê³„ì¹˜ MB (ê¸°ë³¸ê°’: 1)
    --help                 ì´ ë„ì›€ë§ í‘œì‹œ

í™˜ê²½ ë³€ìˆ˜:
    GITHUB_TOKEN                    GitHub API í† í°
    CI_ERROR_ANALYZER_DAYS          ë¶„ì„ ì¼ìˆ˜
    CI_ERROR_ANALYZER_FORMAT        ì¶œë ¥ í˜•ì‹
    CI_ERROR_ANALYZER_DRY_RUN       ë“œë¼ì´ëŸ° ëª¨ë“œ (true/false)
    CI_ERROR_ANALYZER_VERBOSE       ìƒì„¸ ë¡œê·¸ (true/false)
    CI_ERROR_ANALYZER_OUTPUT_DIR    ì¶œë ¥ ë””ë ‰í† ë¦¬
    CI_ERROR_ANALYZER_COMPRESS_MB   ì••ì¶• ì„ê³„ì¹˜ (MB)
    CI_ERROR_ANALYZER_ALERT_ENABLED ì•Œë¦¼ í™œì„±í™” (true/false)

ì˜ˆì‹œ:
    # ê¸°ë³¸ ë¶„ì„ (ìµœê·¼ 7ì¼)
    ./scripts/ci_error_analyzer.sh

    # JSON í˜•ì‹ìœ¼ë¡œ ìµœê·¼ 14ì¼ ë¶„ì„
    ./scripts/ci_error_analyzer.sh --days 14 --format json

    # ë“œë¼ì´ëŸ° ëª¨ë“œë¡œ ìƒì„¸ ë¡œê·¸ í¬í•¨
    ./scripts/ci_error_analyzer.sh --dry-run --verbose

    # ì•Œë¦¼ ì—†ì´ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
    ./scripts/ci_error_analyzer.sh --format markdown --no-alert

ì¶œë ¥:
    - CI/CD ì—ëŸ¬ í†µê³„ ìš”ì•½
    - ì‹¤íŒ¨ ë¹Œë“œ/í…ŒìŠ¤íŠ¸ Top 10 ì›ì¸
    - ì—ëŸ¬ ìœ í˜•ë³„ ë¹ˆë„ ì§‘ê³„
    - ëŒ€ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼ ì••ì¶• ê²°ê³¼
    - ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
EOF
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¸ìˆ˜ íŒŒì‹±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --days)
                DAYS="$2"
                shift 2
                ;;
            --format)
                OUTPUT_FORMAT="$2"
                shift 2
                ;;
            --output-dir)
                OUTPUT_DIR="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN="true"
                shift
                ;;
            --verbose)
                VERBOSE="true"
                shift
                ;;
            --no-alert)
                ALERT_ENABLED="false"
                shift
                ;;
            --compress-mb)
                COMPRESS_THRESHOLD="$2"
                shift 2
                ;;
            --help)
                show_help
                exit 0
                ;;
            *)
                die "ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: $1. --helpë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ì›€ë§ì„ í™•ì¸í•˜ì„¸ìš”."
                ;;
        esac
    done
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜ì¡´ì„± í™•ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
check_dependencies() {
    local deps=("jq" "curl" "gzip" "python3")

    for dep in "${deps[@]}"; do
        if ! command -v "$dep" &> /dev/null; then
            die "í•„ìˆ˜ ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ: $dep"
        fi
    done

    if [[ -z "$GITHUB_TOKEN" ]]; then
        log_warn "GITHUB_TOKENì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ. ê³µê°œ ë¦¬í¬ì§€í† ë¦¬ ì œí•œ ì ìš©."
    fi

    log_debug "ì˜ì¡´ì„± í™•ì¸ ì™„ë£Œ"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë””ë ‰í† ë¦¬ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
setup_directories() {
    local dirs=(
        "$OUTPUT_DIR"
        "$OUTPUT_DIR/logs"
        "$OUTPUT_DIR/reports"
        "$OUTPUT_DIR/compressed"
    )

    for dir in "${dirs[@]}"; do
        if [[ "$DRY_RUN" == "false" ]]; then
            mkdir -p "$dir"
            log_debug "ë””ë ‰í† ë¦¬ ìƒì„±: $dir"
        else
            log_debug "[DRY-RUN] ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë®¬ë ˆì´ì…˜: $dir"
        fi
    done
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GitHub Actions ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´ ìˆ˜ì§‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fetch_workflow_runs() {
    local days="$1"
    local since_date
    since_date=$(date -d "${days} days ago" -u +"%Y-%m-%dT%H:%M:%SZ" 2>/dev/null || date -u -v-${days}d +"%Y-%m-%dT%H:%M:%SZ")

    log_info "GitHub Actions ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´ ìˆ˜ì§‘ ì¤‘... (ìµœê·¼ ${days}ì¼)"

    local api_url="https://api.github.com/repos/youareplan/mcp-map-company/actions/runs"
    local auth_header=""

    if [[ -n "$GITHUB_TOKEN" ]]; then
        auth_header="-H \"Authorization: token $GITHUB_TOKEN\""
    fi

    local runs_data
    if runs_data=$(eval curl -s $auth_header \
        "\"$api_url?created=>\${since_date}&per_page=100\""); then
        echo "$runs_data" > "$OUTPUT_DIR/workflow_runs.json"
        log_success "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ"

        # ì‹¤í–‰ ìƒíƒœë³„ í†µê³„
        local total_runs failed_runs success_runs
        total_runs=$(echo "$runs_data" | jq '.total_count // 0')
        failed_runs=$(echo "$runs_data" | jq '[.workflow_runs[] | select(.conclusion == "failure")] | length')
        success_runs=$(echo "$runs_data" | jq '[.workflow_runs[] | select(.conclusion == "success")] | length')

        log_debug "ì´ ì‹¤í–‰: $total_runs, ì„±ê³µ: $success_runs, ì‹¤íŒ¨: $failed_runs"

        return 0
    else
        log_error "GitHub API í˜¸ì¶œ ì‹¤íŒ¨"
        return 1
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤íŒ¨í•œ ì›Œí¬í”Œë¡œìš° ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
download_failed_logs() {
    if [[ ! -f "$OUTPUT_DIR/workflow_runs.json" ]]; then
        log_error "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
        return 1
    fi

    log_info "ì‹¤íŒ¨í•œ ì›Œí¬í”Œë¡œìš° ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."

    local failed_runs
    failed_runs=$(jq -r '.workflow_runs[] | select(.conclusion == "failure") | "\(.id)|\(.name)|\(.head_branch)"' "$OUTPUT_DIR/workflow_runs.json")

    local download_count=0
    while IFS='|' read -r run_id run_name branch; do
        if [[ -z "$run_id" ]]; then continue; fi

        log_debug "ë‹¤ìš´ë¡œë“œ ì¤‘: $run_name (ID: $run_id, ë¸Œëœì¹˜: $branch)"

        local log_file="$OUTPUT_DIR/logs/run_${run_id}_${run_name//[^a-zA-Z0-9]/_}.log"

        if [[ "$DRY_RUN" == "false" ]]; then
            local auth_header=""
            if [[ -n "$GITHUB_TOKEN" ]]; then
                auth_header="-H \"Authorization: token $GITHUB_TOKEN\""
            fi

            # GitHub Actions ë¡œê·¸ URL (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì ì ˆí•œ API ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
            local log_url="https://api.github.com/repos/youareplan/mcp-map-company/actions/runs/$run_id/logs"

            if eval curl -s $auth_header -L "\"$log_url\"" > "$log_file" 2>/dev/null; then
                ((download_count++))
                log_debug "ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: $log_file"
            else
                log_warn "ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: $run_id"
            fi
        else
            log_debug "[DRY-RUN] ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜: $log_file"
            ((download_count++))
        fi
    done <<< "$failed_runs"

    log_success "ì´ ${download_count}ê°œ ì‹¤íŒ¨ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
analyze_error_patterns() {
    log_info "ì—ëŸ¬ íŒ¨í„´ ë¶„ì„ ì¤‘..."

    local log_dir="$OUTPUT_DIR/logs"
    local analysis_file="$OUTPUT_DIR/error_analysis.json"

    # Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¡œê·¸ ë¶„ì„
    cat > "$OUTPUT_DIR/analyze_errors.py" << 'EOF'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CI/CD ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import re
import os
import sys
from collections import defaultdict, Counter
from pathlib import Path
import gzip

def analyze_log_file(log_path):
    """ê°œë³„ ë¡œê·¸ íŒŒì¼ ë¶„ì„"""
    errors = []
    error_types = defaultdict(int)

    try:
        # gzip íŒŒì¼ ì²˜ë¦¬
        if log_path.suffix == '.gz':
            with gzip.open(log_path, 'rt', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        else:
            with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

        lines = content.split('\n')

        for i, line in enumerate(lines):
            line = line.strip()

            # ì—ëŸ¬ íŒ¨í„´ ë§¤ì¹­
            error_patterns = [
                (r'(?i)error\s*:\s*(.+)', 'BUILD_ERROR'),
                (r'(?i)test\s+failed\s*:\s*(.+)', 'TEST_FAILURE'),
                (r'(?i)assertion\s+failed\s*:\s*(.+)', 'ASSERTION_ERROR'),
                (r'(?i)timeout\s*:\s*(.+)', 'TIMEOUT_ERROR'),
                (r'(?i)out\s+of\s+memory\s*:\s*(.+)', 'MEMORY_ERROR'),
                (r'(?i)permission\s+denied\s*:\s*(.+)', 'PERMISSION_ERROR'),
                (r'(?i)module\s+not\s+found\s*:\s*(.+)', 'MODULE_ERROR'),
                (r'(?i)syntax\s+error\s*:\s*(.+)', 'SYNTAX_ERROR'),
                (r'(?i)deployment\s+failed\s*:\s*(.+)', 'DEPLOY_ERROR'),
                (r'(?i)connection\s+refused\s*:\s*(.+)', 'CONNECTION_ERROR'),
            ]

            for pattern, error_type in error_patterns:
                match = re.search(pattern, line)
                if match:
                    error_msg = match.group(1) if len(match.groups()) > 0 else line
                    errors.append({
                        'type': error_type,
                        'message': error_msg[:200],  # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
                        'line_number': i + 1,
                        'context': lines[max(0, i-1):i+2] if i > 0 else [line]
                    })
                    error_types[error_type] += 1
                    break

    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {log_path}: {e}", file=sys.stderr)

    return errors, dict(error_types)

def main():
    import argparse

    parser = argparse.ArgumentParser(description='CI/CD ë¡œê·¸ ì—ëŸ¬ ë¶„ì„')
    parser.add_argument('--log-dir', required=True, help='ë¡œê·¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output', required=True, help='ì¶œë ¥ JSON íŒŒì¼')
    parser.add_argument('--verbose', action='store_true', help='ìƒì„¸ ì¶œë ¥')

    args = parser.parse_args()

    log_dir = Path(args.log_dir)
    if not log_dir.exists():
        print(f"ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {log_dir}", file=sys.stderr)
        sys.exit(1)

    all_errors = []
    all_error_types = defaultdict(int)
    processed_files = 0

    # ë¡œê·¸ íŒŒì¼ ì²˜ë¦¬
    for log_file in log_dir.glob('*.log*'):
        if args.verbose:
            print(f"ë¶„ì„ ì¤‘: {log_file}", file=sys.stderr)

        errors, error_types = analyze_log_file(log_file)

        all_errors.extend([{
            **error,
            'source_file': str(log_file.name)
        } for error in errors])

        for error_type, count in error_types.items():
            all_error_types[error_type] += count

        processed_files += 1

    # ì—ëŸ¬ ë¹ˆë„ìˆœ ì •ë ¬ (Top 10)
    top_errors = Counter()
    for error in all_errors:
        top_errors[error['message']] += 1

    # ê²°ê³¼ ìƒì„±
    result = {
        'analysis_summary': {
            'processed_files': processed_files,
            'total_errors': len(all_errors),
            'unique_error_types': len(all_error_types),
            'top_error_types': dict(sorted(all_error_types.items(), key=lambda x: x[1], reverse=True)[:10])
        },
        'top_10_errors': [
            {'message': msg, 'count': count}
            for msg, count in top_errors.most_common(10)
        ],
        'error_distribution': dict(all_error_types),
        'detailed_errors': all_errors[:50]  # ìƒìœ„ 50ê°œë§Œ ì €ì¥
    }

    # JSON ì¶œë ¥
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    if args.verbose:
        print(f"ë¶„ì„ ì™„ë£Œ: ì´ {len(all_errors)}ê°œ ì—ëŸ¬ ë°œê²¬ ({processed_files}ê°œ íŒŒì¼)", file=sys.stderr)

if __name__ == '__main__':
    main()
EOF

    # Python ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    if [[ "$DRY_RUN" == "false" ]]; then
        python3 "$OUTPUT_DIR/analyze_errors.py" \
            --log-dir "$log_dir" \
            --output "$analysis_file" \
            $([ "$VERBOSE" == "true" ] && echo "--verbose")

        if [[ -f "$analysis_file" ]]; then
            log_success "ì—ëŸ¬ ë¶„ì„ ì™„ë£Œ: $analysis_file"
        else
            log_error "ì—ëŸ¬ ë¶„ì„ ì‹¤íŒ¨"
            return 1
        fi
    else
        log_debug "[DRY-RUN] ì—ëŸ¬ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜"
        # ë“œë¼ì´ëŸ° ëª¨ë“œì—ì„œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        cat > "$analysis_file" << 'EOF'
{
  "analysis_summary": {
    "processed_files": 5,
    "total_errors": 23,
    "unique_error_types": 4,
    "top_error_types": {
      "TEST_FAILURE": 12,
      "BUILD_ERROR": 7,
      "TIMEOUT_ERROR": 3,
      "MODULE_ERROR": 1
    }
  },
  "top_10_errors": [
    {"message": "test_user_authentication failed", "count": 5},
    {"message": "build timeout after 30 minutes", "count": 3},
    {"message": "module 'requests' not found", "count": 2}
  ],
  "error_distribution": {
    "TEST_FAILURE": 12,
    "BUILD_ERROR": 7,
    "TIMEOUT_ERROR": 3,
    "MODULE_ERROR": 1
  }
}
EOF
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëŒ€ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼ ì••ì¶•
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
compress_large_logs() {
    log_info "ëŒ€ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼ ì••ì¶• ì¤‘... (ì„ê³„ì¹˜: ${COMPRESS_THRESHOLD}MB)"

    local log_dir="$OUTPUT_DIR/logs"
    local compressed_dir="$OUTPUT_DIR/compressed"
    local compressed_count=0
    local total_saved=0

    if [[ ! -d "$log_dir" ]]; then
        log_warn "ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: $log_dir"
        return 0
    fi

    # MBë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    local threshold_bytes=$((COMPRESS_THRESHOLD * 1024 * 1024))

    while IFS= read -r -d '' log_file; do
        local file_size
        file_size=$(stat -f%z "$log_file" 2>/dev/null || stat -c%s "$log_file" 2>/dev/null || echo "0")

        if [[ "$file_size" -gt "$threshold_bytes" ]]; then
            local basename
            basename=$(basename "$log_file")
            local compressed_file="$compressed_dir/${basename}.gz"

            log_debug "ì••ì¶• ì¤‘: $log_file ($(echo "scale=2; $file_size/1024/1024" | bc 2>/dev/null || echo "N/A")MB)"

            if [[ "$DRY_RUN" == "false" ]]; then
                if gzip -c "$log_file" > "$compressed_file"; then
                    local compressed_size
                    compressed_size=$(stat -f%z "$compressed_file" 2>/dev/null || stat -c%s "$compressed_file" 2>/dev/null || echo "0")
                    local saved=$((file_size - compressed_size))

                    rm -f "$log_file"
                    ((compressed_count++))
                    total_saved=$((total_saved + saved))

                    log_debug "ì••ì¶• ì™„ë£Œ: $compressed_file (ì ˆì•½: $(echo "scale=2; $saved/1024/1024" | bc 2>/dev/null || echo "N/A")MB)"
                else
                    log_warn "ì••ì¶• ì‹¤íŒ¨: $log_file"
                fi
            else
                log_debug "[DRY-RUN] ì••ì¶• ì‹œë®¬ë ˆì´ì…˜: $log_file"
                ((compressed_count++))
                total_saved=$((total_saved + file_size / 2))  # ì¶”ì • ì••ì¶•ë¥  50%
            fi
        fi
    done < <(find "$log_dir" -name "*.log" -type f -print0 2>/dev/null)

    if [[ "$compressed_count" -gt 0 ]]; then
        log_success "ì´ ${compressed_count}ê°œ íŒŒì¼ ì••ì¶• ì™„ë£Œ (ì ˆì•½: $(echo "scale=2; $total_saved/1024/1024" | bc 2>/dev/null || echo "N/A")MB)"
    else
        log_info "ì••ì¶• ëŒ€ìƒ íŒŒì¼ ì—†ìŒ"
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¦¬í¬íŠ¸ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
generate_report() {
    local format="$1"
    local timestamp
    timestamp=$(date '+%Y%m%d_%H%M%S')

    log_info "ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... (í˜•ì‹: $format)"

    local analysis_file="$OUTPUT_DIR/error_analysis.json"
    if [[ ! -f "$analysis_file" ]]; then
        log_error "ì—ëŸ¬ ë¶„ì„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: $analysis_file"
        return 1
    fi

    case "$format" in
        "json")
            generate_json_report "$timestamp"
            ;;
        "markdown")
            generate_markdown_report "$timestamp"
            ;;
        "text")
            generate_text_report "$timestamp"
            ;;
        *)
            log_error "ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: $format"
            return 1
            ;;
    esac
}

generate_json_report() {
    local timestamp="$1"
    local output_file="$OUTPUT_DIR/reports/ci_error_report_${timestamp}.json"

    local analysis_data
    analysis_data=$(cat "$OUTPUT_DIR/error_analysis.json")

    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ JSON ë¦¬í¬íŠ¸ ìƒì„±
    jq -n \
        --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
        --arg days "$DAYS" \
        --arg format "$OUTPUT_FORMAT" \
        --argjson analysis "$analysis_data" \
        '{
            generated_at: $timestamp,
            analysis_period_days: ($days | tonumber),
            format: $format,
            summary: $analysis.analysis_summary,
            top_errors: $analysis.top_10_errors,
            error_distribution: $analysis.error_distribution,
            detailed_errors: $analysis.detailed_errors
        }' > "$output_file"

    log_success "JSON ë¦¬í¬íŠ¸ ìƒì„±: $output_file"
}

generate_markdown_report() {
    local timestamp="$1"
    local output_file="$OUTPUT_DIR/reports/ci_error_report_${timestamp}.md"

    local analysis_data
    analysis_data=$(cat "$OUTPUT_DIR/error_analysis.json")

    cat > "$output_file" << EOF
# ğŸš¨ CI/CD ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸

**ìƒì„± ì¼ì‹œ:** $(date '+%Y-%m-%d %H:%M:%S %Z')
**ë¶„ì„ ê¸°ê°„:** ìµœê·¼ ${DAYS}ì¼
**ë¦¬í¬íŠ¸ í˜•ì‹:** Markdown

## ğŸ“Š ë¶„ì„ ìš”ì•½

$(echo "$analysis_data" | jq -r '
"- **ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜:** \(.analysis_summary.processed_files)ê°œ",
"- **ì´ ì—ëŸ¬ ìˆ˜:** \(.analysis_summary.total_errors)ê°œ",
"- **ê³ ìœ  ì—ëŸ¬ ìœ í˜•:** \(.analysis_summary.unique_error_types)ê°œ"
')

## ğŸ”¥ ìƒìœ„ ì—ëŸ¬ ìœ í˜• ë¶„í¬

$(echo "$analysis_data" | jq -r '.analysis_summary.top_error_types | to_entries[] | "- **\(.key):** \(.value)íšŒ"')

## ğŸ“‹ Top 10 ì—ëŸ¬ ë©”ì‹œì§€

$(echo "$analysis_data" | jq -r '.top_10_errors[] | "### \(.count)íšŒ: \(.message)\n"')

## ğŸ“ˆ ì—ëŸ¬ ìœ í˜•ë³„ ìƒì„¸ ë¶„í¬

$(echo "$analysis_data" | jq -r '.error_distribution | to_entries[] | "- \(.key): \(.value)íšŒ"')

## ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´

$(echo "$analysis_data" | jq -r '.detailed_errors[0:5][] | "### \(.type): \(.message)\n**ì†ŒìŠ¤ íŒŒì¼:** \(.source_file)  \n**ë¼ì¸:** \(.line_number)\n"')

---

**ë¦¬í¬íŠ¸ ìƒì„±:** MCP-MAP CI ì—ëŸ¬ ë¶„ì„ê¸° v1.0
**ë¬¸ì˜:** CI/CD íŒ€
EOF

    log_success "Markdown ë¦¬í¬íŠ¸ ìƒì„±: $output_file"
}

generate_text_report() {
    local timestamp="$1"
    local output_file="$OUTPUT_DIR/reports/ci_error_report_${timestamp}.txt"

    local analysis_data
    analysis_data=$(cat "$OUTPUT_DIR/error_analysis.json")

    cat > "$output_file" << EOF
==========================================
ğŸš¨ MCP-MAP CI/CD ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸
==========================================

ìƒì„± ì¼ì‹œ: $(date '+%Y-%m-%d %H:%M:%S %Z')
ë¶„ì„ ê¸°ê°„: ìµœê·¼ ${DAYS}ì¼
ë¦¬í¬íŠ¸ í˜•ì‹: í…ìŠ¤íŠ¸

ğŸ“Š ë¶„ì„ ìš”ì•½
----------------------------------------
$(echo "$analysis_data" | jq -r '
"ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: \(.analysis_summary.processed_files)ê°œ",
"ì´ ì—ëŸ¬ ìˆ˜: \(.analysis_summary.total_errors)ê°œ",
"ê³ ìœ  ì—ëŸ¬ ìœ í˜•: \(.analysis_summary.unique_error_types)ê°œ"
')

ğŸ”¥ ìƒìœ„ ì—ëŸ¬ ìœ í˜• ë¶„í¬
----------------------------------------
$(echo "$analysis_data" | jq -r '.analysis_summary.top_error_types | to_entries[] | "\(.key): \(.value)íšŒ"')

ğŸ“‹ Top 10 ì—ëŸ¬ ë©”ì‹œì§€
----------------------------------------
$(echo "$analysis_data" | jq -r '.top_10_errors[] | "\(.count)íšŒ: \(.message)"')

==========================================
ë¦¬í¬íŠ¸ ìƒì„±: MCP-MAP CI ì—ëŸ¬ ë¶„ì„ê¸° v1.0
EOF

    log_success "í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±: $output_file"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì•Œë¦¼ ì „ì†¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
send_alerts() {
    if [[ "$ALERT_ENABLED" != "true" ]]; then
        log_info "ì•Œë¦¼ ì „ì†¡ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        return 0
    fi

    log_info "ì—ëŸ¬ ë¶„ì„ ê²°ê³¼ ì•Œë¦¼ ì „ì†¡ ì¤‘..."

    local analysis_file="$OUTPUT_DIR/error_analysis.json"
    if [[ ! -f "$analysis_file" ]]; then
        log_warn "ë¶„ì„ íŒŒì¼ì´ ì—†ì–´ ì•Œë¦¼ì„ ì „ì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return 0
    fi

    # ì‹¤íŒ¨ìœ¨ ê³„ì‚° (ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°)
    local failure_rate=0
    if [[ -f "$OUTPUT_DIR/workflow_runs.json" ]]; then
        local total_runs failed_runs
        total_runs=$(jq '.total_count // 0' "$OUTPUT_DIR/workflow_runs.json")
        failed_runs=$(jq '[.workflow_runs[] | select(.conclusion == "failure")] | length' "$OUTPUT_DIR/workflow_runs.json")

        if [[ "$total_runs" -gt 0 ]]; then
            failure_rate=$(echo "scale=2; $failed_runs * 100 / $total_runs" | bc 2>/dev/null || echo "0")
        fi
    fi

    # notifier.pyì˜ send_ci_error_alert í•¨ìˆ˜ í˜¸ì¶œ
    if [[ "$DRY_RUN" == "false" ]]; then
        if python3 -c "
import sys
import os
sys.path.append('$PROJECT_ROOT')
from mcp.utils.notifier import send_ci_error_alert_sync
import json

with open('$analysis_file', 'r') as f:
    analysis = json.load(f)

send_ci_error_alert_sync(
    failure_rate=$failure_rate,
    total_errors=analysis['analysis_summary']['total_errors'],
    top_errors=analysis['top_10_errors'][:3],
    period_days=$DAYS
)
"; then
            log_success "ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ"
        else
            log_warn "ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨"
        fi
    else
        log_debug "[DRY-RUN] ì•Œë¦¼ ì „ì†¡ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤íŒ¨ìœ¨: ${failure_rate}%)"
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì •ë¦¬ ì‘ì—…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cleanup() {
    log_debug "ì •ë¦¬ ì‘ì—… ìˆ˜í–‰ ì¤‘..."

    # ì„ì‹œ Python ìŠ¤í¬ë¦½íŠ¸ ì œê±°
    if [[ -f "$OUTPUT_DIR/analyze_errors.py" ]]; then
        rm -f "$OUTPUT_DIR/analyze_errors.py"
    fi

    # 7ì¼ ì´ìƒ ëœ ë¦¬í¬íŠ¸ íŒŒì¼ ì •ë¦¬
    if [[ "$DRY_RUN" == "false" ]]; then
        find "$OUTPUT_DIR/reports" -name "ci_error_report_*.{json,md,txt}" -type f -mtime +7 -delete 2>/dev/null || true
        find "$OUTPUT_DIR/logs" -name "*.log" -type f -mtime +7 -delete 2>/dev/null || true
    fi

    log_debug "ì •ë¦¬ ì‘ì—… ì™„ë£Œ"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
main() {
    local start_time
    start_time=$(date +%s)

    echo -e "${CYAN}"
    cat << 'EOF'
ğŸš¨ MCP-MAP CI/CD ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ê¸° ì‹œì‘
========================================
EOF
    echo -e "${NC}"

    log_info "ë¶„ì„ ì„¤ì •:"
    log_info "  - ë¶„ì„ ê¸°ê°„: ${DAYS}ì¼"
    log_info "  - ì¶œë ¥ í˜•ì‹: ${OUTPUT_FORMAT}"
    log_info "  - ì¶œë ¥ ë””ë ‰í† ë¦¬: ${OUTPUT_DIR}"
    log_info "  - ë“œë¼ì´ëŸ° ëª¨ë“œ: ${DRY_RUN}"
    log_info "  - ì••ì¶• ì„ê³„ì¹˜: ${COMPRESS_THRESHOLD}MB"
    log_info "  - ì•Œë¦¼ ì „ì†¡: ${ALERT_ENABLED}"

    # ì‹¤í–‰ ë‹¨ê³„
    check_dependencies
    setup_directories

    if fetch_workflow_runs "$DAYS"; then
        download_failed_logs
    else
        log_warn "GitHub API ì ‘ê·¼ ì‹¤íŒ¨. ë¡œì»¬ ë¡œê·¸ íŒŒì¼ë§Œ ë¶„ì„í•©ë‹ˆë‹¤."
    fi

    analyze_error_patterns
    compress_large_logs
    generate_report "$OUTPUT_FORMAT"
    send_alerts
    cleanup

    local end_time duration
    end_time=$(date +%s)
    duration=$((end_time - start_time))

    echo -e "${GREEN}"
    cat << EOF
ğŸ‰ CI/CD ì—ëŸ¬ ë¶„ì„ ì™„ë£Œ!
========================================
ì‹¤í–‰ ì‹œê°„: ${duration}ì´ˆ
ì¶œë ¥ ë””ë ‰í† ë¦¬: ${OUTPUT_DIR}
ìƒì„±ëœ ë¦¬í¬íŠ¸: ${OUTPUT_DIR}/reports/
EOF
    echo -e "${NC}"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    # ì¸ìˆ˜ íŒŒì‹±
    parse_args "$@"

    # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    main
fi