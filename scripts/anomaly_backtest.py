#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ” ì´ìƒíƒì§€ ë°±í…ŒìŠ¤íŠ¸ ë° íŒŒë¼ë¯¸í„° íŠœë‹ ìŠ¤í¬ë¦½íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)

ì£¼ìš” ê¸°ëŠ¥:
- CSV/JSON ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì´ìš©í•œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- Z-score ì„ê³„ê°’, EWMA ì•ŒíŒŒ, ìœˆë„ìš° í¬ê¸° ë“± íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜
- ì¬í˜„ìœ¨(Recall), ì •ë°€ë„(Precision), F1 ì ìˆ˜, ì•Œë¦¼ëŸ‰ ë“± ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
- ê³¼íƒì§€ìœ¨, ë¯¸íƒì§€ìœ¨ ë¶„ì„ ë° ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì²œ
- Markdown/JSON í˜•ì‹ ë¦¬í¬íŠ¸ ìƒì„±

ì‚¬ìš©ë²•:
    python scripts/anomaly_backtest.py --input data.csv --format csv
    python scripts/anomaly_backtest.py --input data.json --grid comprehensive --json
    python scripts/anomaly_backtest.py --help

ì‘ì„±ì: Claude Code Assistant
ìƒì„±ì¼: 2024-09-21
"""

import argparse
import json
import csv
import logging
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional, Union

import numpy as np
import pandas as pd
from dataclasses import dataclass, asdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from mcp.anomaly_rca import AnomalyRCAAnalyzer
except ImportError:
    print("âŒ mcp.anomaly_rca ëª¨ë“ˆì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

@dataclass
class BacktestConfig:
    """ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    input_file: str
    format: str = "csv"  # csv, json
    grid_preset: str = "basic"  # basic, comprehensive, custom
    output_format: str = "markdown"  # markdown, json, both
    output_file: Optional[str] = None
    dry_run: bool = False
    verbose: bool = False

@dataclass
class ParameterSet:
    """íŒŒë¼ë¯¸í„° ì„¸íŠ¸"""
    threshold: float
    window_size: int
    ewma_alpha: float
    forecast_days: int = 7

@dataclass
class BacktestResult:
    """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    parameters: ParameterSet
    precision: float
    recall: float
    f1_score: float
    total_alerts: int
    false_positive_rate: float
    false_negative_rate: float
    execution_time: float
    detected_anomalies: int
    missed_anomalies: int

@dataclass
class BacktestSummary:
    """ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½"""
    best_parameters: ParameterSet
    best_f1_score: float
    total_combinations: int
    execution_time: float
    data_points: int
    recommendation: str
    performance_matrix: List[BacktestResult]

class AnomalyBacktester:
    """ì´ìƒíƒì§€ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""

    def __init__(self, config: BacktestConfig):
        """ì´ˆê¸°í™”"""
        self.config = config
        self.data = None
        self.ground_truth = None  # ì‹¤ì œ ì´ìƒì¹˜ ë¼ë²¨
        self.logger = logging.getLogger(f"{__name__}.AnomalyBacktester")

    def load_data(self) -> bool:
        """ë°ì´í„° ë¡œë“œ"""
        try:
            file_path = Path(self.config.input_file)
            if not file_path.exists():
                self.logger.error(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                return False

            if self.config.format.lower() == "csv":
                return self._load_csv_data(file_path)
            elif self.config.format.lower() == "json":
                return self._load_json_data(file_path)
            else:
                self.logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {self.config.format}")
                return False

        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _load_csv_data(self, file_path: Path) -> bool:
        """CSV ë°ì´í„° ë¡œë“œ"""
        try:
            df = pd.read_csv(file_path)

            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['timestamp', 'value']
            if not all(col in df.columns for col in required_cols):
                self.logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {required_cols}")
                return False

            self.data = {
                'timestamps': df['timestamp'].tolist(),
                'values': df['value'].tolist()
            }

            # ì‹¤ì œ ì´ìƒì¹˜ ë¼ë²¨ì´ ìˆëŠ” ê²½ìš° ë¡œë“œ
            if 'is_anomaly' in df.columns:
                self.ground_truth = df['is_anomaly'].astype(bool).tolist()
                self.logger.info(f"ì‹¤ì œ ì´ìƒì¹˜ ë¼ë²¨ ë¡œë“œ: {sum(self.ground_truth)}ê°œ")
            else:
                self.logger.warning("ì‹¤ì œ ì´ìƒì¹˜ ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. í•©ì„± ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                self.ground_truth = self._generate_synthetic_labels()

            self.logger.info(f"CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data['values'])}ê°œ í¬ì¸íŠ¸")
            return True

        except Exception as e:
            self.logger.error(f"CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _load_json_data(self, file_path: Path) -> bool:
        """JSON ë°ì´í„° ë¡œë“œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)

            # í˜•ì‹ í™•ì¸ ë° ë³€í™˜
            if isinstance(json_data, dict):
                if 'data' in json_data:
                    # {data: [{timestamp, value, is_anomaly?}, ...]} í˜•ì‹
                    data_list = json_data['data']
                    self.data = {
                        'timestamps': [item.get('timestamp', f'T{i}') for i, item in enumerate(data_list)],
                        'values': [item['value'] for item in data_list]
                    }

                    if 'is_anomaly' in data_list[0]:
                        self.ground_truth = [item['is_anomaly'] for item in data_list]
                elif 'values' in json_data:
                    # {timestamps: [...], values: [...], labels?: [...]} í˜•ì‹
                    self.data = {
                        'timestamps': json_data.get('timestamps', [f'T{i}' for i in range(len(json_data['values']))]),
                        'values': json_data['values']
                    }
                    self.ground_truth = json_data.get('labels')
            elif isinstance(json_data, list):
                # ë‹¨ìˆœ ê°’ ë°°ì—´ í˜•ì‹
                self.data = {
                    'timestamps': [f'T{i}' for i in range(len(json_data))],
                    'values': json_data
                }

            if self.ground_truth is None:
                self.logger.warning("ì‹¤ì œ ì´ìƒì¹˜ ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. í•©ì„± ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                self.ground_truth = self._generate_synthetic_labels()

            self.logger.info(f"JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data['values'])}ê°œ í¬ì¸íŠ¸")
            return True

        except Exception as e:
            self.logger.error(f"JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _generate_synthetic_labels(self) -> List[bool]:
        """í•©ì„± ì´ìƒì¹˜ ë¼ë²¨ ìƒì„± (Z-score 3.0 ê¸°ì¤€)"""
        values = np.array(self.data['values'])
        mean_val = np.mean(values)
        std_val = np.std(values)

        if std_val == 0:
            return [False] * len(values)

        z_scores = np.abs((values - mean_val) / std_val)
        return (z_scores > 3.0).tolist()

    def get_parameter_grid(self) -> List[ParameterSet]:
        """íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ìƒì„±"""
        if self.config.grid_preset == "basic":
            return self._get_basic_grid()
        elif self.config.grid_preset == "comprehensive":
            return self._get_comprehensive_grid()
        else:
            return self._get_custom_grid()

    def _get_basic_grid(self) -> List[ParameterSet]:
        """ê¸°ë³¸ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ"""
        grid = []

        for threshold in [2.0, 2.5, 3.0, 3.5]:
            for window_size in [5, 7, 10]:
                for ewma_alpha in [0.2, 0.3, 0.5]:
                    grid.append(ParameterSet(
                        threshold=threshold,
                        window_size=window_size,
                        ewma_alpha=ewma_alpha,
                        forecast_days=7
                    ))

        return grid

    def _get_comprehensive_grid(self) -> List[ParameterSet]:
        """í¬ê´„ì  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ"""
        grid = []

        for threshold in [1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]:
            for window_size in [3, 5, 7, 10, 14]:
                for ewma_alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.7]:
                    for forecast_days in [3, 7, 14]:
                        grid.append(ParameterSet(
                            threshold=threshold,
                            window_size=window_size,
                            ewma_alpha=ewma_alpha,
                            forecast_days=forecast_days
                        ))

        return grid

    def _get_custom_grid(self) -> List[ParameterSet]:
        """ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)"""
        # í™˜ê²½ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼ì—ì„œ ì»¤ìŠ¤í…€ ê·¸ë¦¬ë“œ ë¡œë“œ
        # í˜„ì¬ëŠ” ê¸°ë³¸ ê·¸ë¦¬ë“œ ë°˜í™˜
        return self._get_basic_grid()

    def run_backtest(self) -> BacktestSummary:
        """ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            start_time = time.time()

            self.logger.info("ğŸ” ì´ìƒíƒì§€ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘...")

            if not self.load_data():
                raise Exception("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

            parameter_grid = self.get_parameter_grid()
            self.logger.info(f"ğŸ“Š íŒŒë¼ë¯¸í„° ì¡°í•© {len(parameter_grid)}ê°œë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘")

            results = []
            best_result = None
            best_f1 = 0.0

            for i, params in enumerate(parameter_grid, 1):
                if self.config.verbose:
                    self.logger.info(f"ì§„í–‰ìƒí™©: {i}/{len(parameter_grid)} - {params}")

                result = self._test_parameters(params)
                results.append(result)

                if result.f1_score > best_f1:
                    best_f1 = result.f1_score
                    best_result = result

            execution_time = time.time() - start_time

            # ì¶”ì²œ ë©”ì‹œì§€ ìƒì„±
            recommendation = self._generate_recommendation(best_result, results)

            summary = BacktestSummary(
                best_parameters=best_result.parameters,
                best_f1_score=best_f1,
                total_combinations=len(parameter_grid),
                execution_time=execution_time,
                data_points=len(self.data['values']),
                recommendation=recommendation,
                performance_matrix=results
            )

            self.logger.info(f"âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ìµœê³  F1 ì ìˆ˜ {best_f1:.3f} (ì‹¤í–‰ì‹œê°„: {execution_time:.1f}ì´ˆ)")

            return summary

        except Exception as e:
            self.logger.error(f"ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise

    def _test_parameters(self, params: ParameterSet) -> BacktestResult:
        """ê°œë³„ íŒŒë¼ë¯¸í„° ì„¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()

        try:
            # ê°„ë‹¨í•œ ì´ìƒíƒì§€ ì‹œë®¬ë ˆì´ì…˜
            values = np.array(self.data['values'])
            detected_anomalies = []

            # EWMA ì ìš©
            ewma = np.zeros_like(values)
            ewma[0] = values[0]
            for i in range(1, len(values)):
                ewma[i] = params.ewma_alpha * values[i] + (1 - params.ewma_alpha) * ewma[i-1]

            # ë¡¤ë§ ìœˆë„ìš°ë¡œ ì´ìƒíƒì§€
            for i in range(params.window_size, len(values)):
                window_data = ewma[i-params.window_size:i]
                mean_val = np.mean(window_data)
                std_val = np.std(window_data)

                if std_val > 0:
                    z_score = abs((ewma[i] - mean_val) / std_val)
                    if z_score >= params.threshold:
                        detected_anomalies.append(i)

            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            predicted = [False] * len(values)
            for idx in detected_anomalies:
                predicted[idx] = True

            precision, recall, f1_score = self._calculate_metrics(self.ground_truth, predicted)

            # ì¶”ê°€ ì§€í‘œ
            false_positives = sum(1 for i, (true, pred) in enumerate(zip(self.ground_truth, predicted))
                                if pred and not true)
            false_negatives = sum(1 for i, (true, pred) in enumerate(zip(self.ground_truth, predicted))
                                if true and not pred)

            total_predicted = sum(predicted)
            total_actual = sum(self.ground_truth)

            false_positive_rate = false_positives / (len(values) - total_actual) if (len(values) - total_actual) > 0 else 0
            false_negative_rate = false_negatives / total_actual if total_actual > 0 else 0

            execution_time = time.time() - start_time

            return BacktestResult(
                parameters=params,
                precision=precision,
                recall=recall,
                f1_score=f1_score,
                total_alerts=total_predicted,
                false_positive_rate=false_positive_rate,
                false_negative_rate=false_negative_rate,
                execution_time=execution_time,
                detected_anomalies=len(detected_anomalies),
                missed_anomalies=false_negatives
            )

        except Exception as e:
            self.logger.warning(f"íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ {params}: {e}")
            return BacktestResult(
                parameters=params,
                precision=0.0,
                recall=0.0,
                f1_score=0.0,
                total_alerts=0,
                false_positive_rate=1.0,
                false_negative_rate=1.0,
                execution_time=time.time() - start_time,
                detected_anomalies=0,
                missed_anomalies=sum(self.ground_truth)
            )

    def _calculate_metrics(self, y_true: List[bool], y_pred: List[bool]) -> Tuple[float, float, float]:
        """ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ ê³„ì‚°"""
        true_positives = sum(1 for true, pred in zip(y_true, y_pred) if true and pred)
        false_positives = sum(1 for true, pred in zip(y_true, y_pred) if not true and pred)
        false_negatives = sum(1 for true, pred in zip(y_true, y_pred) if true and not pred)

        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return precision, recall, f1_score

    def _generate_recommendation(self, best_result: BacktestResult, all_results: List[BacktestResult]) -> str:
        """ì¶”ì²œ ë©”ì‹œì§€ ìƒì„±"""
        if not best_result:
            return "ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë‚˜ ê·¸ë¦¬ë“œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."

        params = best_result.parameters

        # ì„±ëŠ¥ í‰ê°€
        if best_result.f1_score >= 0.8:
            performance = "ìš°ìˆ˜"
        elif best_result.f1_score >= 0.6:
            performance = "ì–‘í˜¸"
        elif best_result.f1_score >= 0.4:
            performance = "ë³´í†µ"
        else:
            performance = "ê°œì„  í•„ìš”"

        # ì¶”ì²œ ë©”ì‹œì§€
        recommendation = f"""
ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì²œ:
- Z-score ì„ê³„ê°’: {params.threshold}
- ìœˆë„ìš° í¬ê¸°: {params.window_size}ì¼
- EWMA ì•ŒíŒŒ: {params.ewma_alpha}
- ì˜ˆì¸¡ ê¸°ê°„: {params.forecast_days}ì¼

ğŸ“Š ì„±ëŠ¥ í‰ê°€: {performance} (F1: {best_result.f1_score:.3f})
- ì •ë°€ë„: {best_result.precision:.3f}
- ì¬í˜„ìœ¨: {best_result.recall:.3f}
- ì¼ì¼ í‰ê·  ì•Œë¦¼: {best_result.total_alerts}ê°œ
- ê³¼íƒì§€ìœ¨: {best_result.false_positive_rate:.1%}
- ë¯¸íƒì§€ìœ¨: {best_result.false_negative_rate:.1%}

ğŸ’¡ ê¶Œì¥ì‚¬í•­:
"""

        # ë§ì¶¤í˜• ê¶Œì¥ì‚¬í•­
        if best_result.false_positive_rate > 0.1:
            recommendation += "- ì„ê³„ê°’ì„ ë†’ì—¬ ê³¼íƒì§€ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.\n"

        if best_result.false_negative_rate > 0.2:
            recommendation += "- ì„ê³„ê°’ì„ ë‚®ì¶° ë¯¸íƒì§€ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.\n"

        if best_result.total_alerts > 50:
            recommendation += "- ì•Œë¦¼ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. ì„œí”„ë ˆì…˜ ë£° ì ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.\n"

        if best_result.execution_time > 5.0:
            recommendation += "- ì²˜ë¦¬ ì‹œê°„ì´ ê¹ë‹ˆë‹¤. ìœˆë„ìš° í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.\n"

        return recommendation.strip()

    def save_results(self, summary: BacktestSummary) -> bool:
        """ê²°ê³¼ ì €ì¥"""
        try:
            if self.config.dry_run:
                self.logger.info("ğŸ” Dry-run ëª¨ë“œ: íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                self._print_summary(summary)
                return True

            output_file = self.config.output_file
            if not output_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"anomaly_backtest_{timestamp}"

            success = True

            if self.config.output_format in ["markdown", "both"]:
                md_file = f"{output_file}.md"
                if self._save_markdown_report(summary, md_file):
                    self.logger.info(f"ğŸ“ Markdown ë¦¬í¬íŠ¸ ì €ì¥: {md_file}")
                else:
                    success = False

            if self.config.output_format in ["json", "both"]:
                json_file = f"{output_file}.json"
                if self._save_json_report(summary, json_file):
                    self.logger.info(f"ğŸ“„ JSON ë¦¬í¬íŠ¸ ì €ì¥: {json_file}")
                else:
                    success = False

            return success

        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _save_markdown_report(self, summary: BacktestSummary, filename: str) -> bool:
        """Markdown ë¦¬í¬íŠ¸ ì €ì¥"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(self._generate_markdown_report(summary))
            return True
        except Exception as e:
            self.logger.error(f"Markdown ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _save_json_report(self, summary: BacktestSummary, filename: str) -> bool:
        """JSON ë¦¬í¬íŠ¸ ì €ì¥"""
        try:
            # dataclassë¥¼ dictë¡œ ë³€í™˜
            json_data = {
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "input_file": self.config.input_file,
                    "data_format": self.config.format,
                    "grid_preset": self.config.grid_preset,
                    "data_points": summary.data_points
                },
                "summary": {
                    "best_parameters": asdict(summary.best_parameters),
                    "best_f1_score": summary.best_f1_score,
                    "total_combinations": summary.total_combinations,
                    "execution_time": summary.execution_time,
                    "recommendation": summary.recommendation
                },
                "results": [asdict(result) for result in summary.performance_matrix[:10]]  # ìƒìœ„ 10ê°œë§Œ
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            self.logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _generate_markdown_report(self, summary: BacktestSummary) -> str:
        """Markdown ë¦¬í¬íŠ¸ ìƒì„±"""
        report = f"""# ğŸ” ì´ìƒíƒì§€ ë°±í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸

ìƒì„±ì¼ì‹œ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½

- **ì…ë ¥ íŒŒì¼**: {self.config.input_file}
- **ë°ì´í„° í¬ì¸íŠ¸**: {summary.data_points:,}ê°œ
- **íŒŒë¼ë¯¸í„° ì¡°í•©**: {summary.total_combinations}ê°œ
- **ì‹¤í–‰ ì‹œê°„**: {summary.execution_time:.1f}ì´ˆ

## ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê°’ |
|---------|-----|
| Z-score ì„ê³„ê°’ | {summary.best_parameters.threshold} |
| ìœˆë„ìš° í¬ê¸° | {summary.best_parameters.window_size}ì¼ |
| EWMA ì•ŒíŒŒ | {summary.best_parameters.ewma_alpha} |
| ì˜ˆì¸¡ ê¸°ê°„ | {summary.best_parameters.forecast_days}ì¼ |

## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ

| ì§€í‘œ | ê°’ |
|------|-----|
| **F1 ì ìˆ˜** | **{summary.best_f1_score:.3f}** |
| ì •ë°€ë„ | {summary.performance_matrix[0].precision:.3f} |
| ì¬í˜„ìœ¨ | {summary.performance_matrix[0].recall:.3f} |
| ì´ ì•Œë¦¼ ìˆ˜ | {summary.performance_matrix[0].total_alerts}ê°œ |
| ê³¼íƒì§€ìœ¨ | {summary.performance_matrix[0].false_positive_rate:.1%} |
| ë¯¸íƒì§€ìœ¨ | {summary.performance_matrix[0].false_negative_rate:.1%} |

## ğŸ’¡ ê¶Œì¥ì‚¬í•­

{summary.recommendation}

## ğŸ“‹ ìƒìœ„ ì„±ëŠ¥ ê²°ê³¼

| ìˆœìœ„ | F1 ì ìˆ˜ | ì„ê³„ê°’ | ìœˆë„ìš° | EWMA | ì •ë°€ë„ | ì¬í˜„ìœ¨ | ì•Œë¦¼ìˆ˜ |
|------|---------|--------|--------|------|--------|--------|--------|
"""

        # ìƒìœ„ 10ê°œ ê²°ê³¼ ì¶”ê°€
        sorted_results = sorted(summary.performance_matrix, key=lambda x: x.f1_score, reverse=True)
        for i, result in enumerate(sorted_results[:10], 1):
            report += f"| {i} | {result.f1_score:.3f} | {result.parameters.threshold} | {result.parameters.window_size} | {result.parameters.ewma_alpha} | {result.precision:.3f} | {result.recall:.3f} | {result.total_alerts} |\n"

        report += f"""

## ğŸ”§ ì‹¤í–‰ ì •ë³´

- **ì‹¤í–‰ ëª…ë ¹**: `python scripts/anomaly_backtest.py --input {self.config.input_file} --format {self.config.format} --grid {self.config.grid_preset}`
- **ì„¤ì •**:
  - ê·¸ë¦¬ë“œ í”„ë¦¬ì…‹: {self.config.grid_preset}
  - ì¶œë ¥ í˜•ì‹: {self.config.output_format}
  - Dry-run ëª¨ë“œ: {self.config.dry_run}
- **ì´ í…ŒìŠ¤íŠ¸ ì‹œê°„**: {summary.execution_time:.1f}ì´ˆ

---
*ì´ ë¦¬í¬íŠ¸ëŠ” anomaly_backtest.py ìŠ¤í¬ë¦½íŠ¸ë¡œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

        return report

    def _print_summary(self, summary: BacktestSummary):
        """ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥"""
        print(f"""
ğŸ” ì´ìƒíƒì§€ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½

ğŸ“Š ë°ì´í„°: {summary.data_points:,}ê°œ í¬ì¸íŠ¸, {summary.total_combinations}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸
â±ï¸  ì‹¤í–‰ì‹œê°„: {summary.execution_time:.1f}ì´ˆ

ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:
   ì„ê³„ê°’: {summary.best_parameters.threshold}
   ìœˆë„ìš°: {summary.best_parameters.window_size}ì¼
   EWMA Î±: {summary.best_parameters.ewma_alpha}

ğŸ“ˆ ìµœê³  ì„±ëŠ¥:
   F1 ì ìˆ˜: {summary.best_f1_score:.3f}
   ì •ë°€ë„: {summary.performance_matrix[0].precision:.3f}
   ì¬í˜„ìœ¨: {summary.performance_matrix[0].recall:.3f}

{summary.recommendation}
""")

def create_sample_data(filename: str = "sample_anomaly_data.csv", size: int = 1000):
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    logger.info(f"ğŸ“ ìƒ˜í”Œ ë°ì´í„° ìƒì„±: {filename} ({size}ê°œ í¬ì¸íŠ¸)")

    np.random.seed(42)

    # ê¸°ë³¸ ì‹œê³„ì—´ + ë…¸ì´ì¦ˆ
    timestamps = [f"2024-09-{(i//24)+1:02d} {i%24:02d}:00:00" for i in range(size)]

    # ì •ìƒ íŒ¨í„´ ìƒì„±
    t = np.arange(size)
    normal_pattern = 50 + 20 * np.sin(2 * np.pi * t / 24) + np.random.normal(0, 5, size)

    # ì´ìƒì¹˜ ì£¼ì… (5% ì •ë„)
    anomaly_indices = np.random.choice(size, size=size//20, replace=False)
    values = normal_pattern.copy()
    is_anomaly = np.zeros(size, dtype=bool)

    for idx in anomaly_indices:
        values[idx] += np.random.choice([-1, 1]) * np.random.uniform(30, 50)
        is_anomaly[idx] = True

    # CSV ì €ì¥
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['timestamp', 'value', 'is_anomaly'])
        for ts, val, anomaly in zip(timestamps, values, is_anomaly):
            writer.writerow([ts, f"{val:.2f}", anomaly])

    logger.info(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: ì´ìƒì¹˜ {sum(is_anomaly)}ê°œ í¬í•¨")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ğŸ” ì´ìƒíƒì§€ ë°±í…ŒìŠ¤íŠ¸ ë° íŒŒë¼ë¯¸í„° íŠœë‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  %(prog)s --input data.csv --format csv
  %(prog)s --input data.json --grid comprehensive --json
  %(prog)s --sample  # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
  %(prog)s --input sample_anomaly_data.csv --grid basic --md
        """
    )

    parser.add_argument('--input', type=str, help='ì…ë ¥ ë°ì´í„° íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--format', choices=['csv', 'json'], default='csv',
                       help='ì…ë ¥ ë°ì´í„° í˜•ì‹ (ê¸°ë³¸ê°’: csv)')
    parser.add_argument('--grid', choices=['basic', 'comprehensive', 'custom'], default='basic',
                       help='íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ í”„ë¦¬ì…‹ (ê¸°ë³¸ê°’: basic)')
    parser.add_argument('--output-file', type=str, help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì ì œì™¸)')
    parser.add_argument('--json', action='store_true', help='JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥')
    parser.add_argument('--md', action='store_true', help='Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥')
    parser.add_argument('--both', action='store_true', help='JSONê³¼ Markdown ëª¨ë‘ ì¶œë ¥')
    parser.add_argument('--dry-run', action='store_true', help='íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šê³  ê²°ê³¼ë§Œ ì¶œë ¥')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ì¶œë ¥')
    parser.add_argument('--sample', action='store_true', help='ìƒ˜í”Œ ë°ì´í„° ìƒì„± í›„ ì¢…ë£Œ')

    args = parser.parse_args()

    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    if args.sample:
        create_sample_data()
        return

    # ì…ë ¥ íŒŒì¼ ê²€ì¦
    if not args.input:
        parser.error("--input íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤ (ë˜ëŠ” --sample ì‚¬ìš©)")

    # ì¶œë ¥ í˜•ì‹ ê²°ì •
    if args.both:
        output_format = "both"
    elif args.json:
        output_format = "json"
    elif args.md:
        output_format = "markdown"
    else:
        output_format = "markdown"  # ê¸°ë³¸ê°’

    # ì„¤ì • ìƒì„±
    config = BacktestConfig(
        input_file=args.input,
        format=args.format,
        grid_preset=args.grid,
        output_format=output_format,
        output_file=args.output_file,
        dry_run=args.dry_run,
        verbose=args.verbose
    )

    try:
        # ë°±í…ŒìŠ¤í„° ì‹¤í–‰
        backtester = AnomalyBacktester(config)
        summary = backtester.run_backtest()

        # ê²°ê³¼ ì €ì¥
        if backtester.save_results(summary):
            logger.info("âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ê²°ê³¼ ì €ì¥ ì„±ê³µ")
        else:
            logger.error("âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()