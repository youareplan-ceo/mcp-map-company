#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ” ì´ìƒíƒì§€ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)

pytest ê¸°ë°˜ì˜ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ëª¨ìŒ:
- ì „ì²˜ë¦¬/ì„ê³„ì¹˜/ìœˆë„ìš° íŒŒë¼ë¯¸í„° ì •í™•ì„± í…ŒìŠ¤íŠ¸
- ì´ìƒíƒì§€ í¬ì¸íŠ¸ ê°œìˆ˜Â·ì¸ë±ìŠ¤ ê²€ì¦
- ì˜ˆì¸¡(íšŒê·€+EWMA) ê²°ê³¼ ë²”ìœ„/ì¦ê°€Â·ê°ì†Œ ì¶”ì„¸ ê²€ì¦
- API ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ/ì˜¤ë¥˜/ê¶Œí•œ í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (10ë§Œ í¬ì¸íŠ¸ ë‚´ 5ì´ˆ ì´ë‚´ ì²˜ë¦¬)

ì‘ì„±ì: MCP Map Company ìš´ì˜íŒ€
ìƒì„±ì¼: 2024ë…„ ì´ìƒíƒì§€ ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸
"""

import asyncio
import json
import os
import subprocess
import sys
import tempfile
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any
import warnings

import pytest
import numpy as np
import pandas as pd
from fastapi.testclient import TestClient

# í˜„ì¬ íŒŒì¼ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

try:
    # ì´ìƒíƒì§€ ìŠ¤í¬ë¦½íŠ¸ ì„í¬íŠ¸
    from scripts.anomaly_detect import AnomalyDetector
    # FastAPI ì•± ì„í¬íŠ¸
    from mcp.run import app
    from mcp.anomaly_api import router
except ImportError as e:
    pytest.skip(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}", allow_module_level=True)

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# ================================================================
# í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

@pytest.fixture
def anomaly_detector():
    """ê¸°ë³¸ ì´ìƒíƒì§€ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return AnomalyDetector(
        window_size=7,
        threshold=3.0,
        forecast_days=7,
        ewma_alpha=0.3
    )

@pytest.fixture
def sample_timeseries_data():
    """í…ŒìŠ¤íŠ¸ìš© ì‹œê³„ì—´ ë°ì´í„° ìƒì„± (ì´ìƒì¹˜ í¬í•¨)"""
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •

    # 30ì¼ê°„ì˜ ì‹œê°„ë‹¹ ë°ì´í„° (720 í¬ì¸íŠ¸)
    dates = pd.date_range(start='2024-01-01', periods=720, freq='H')

    # ê¸°ë³¸ ì‹œê³„ì—´ (íŠ¸ë Œë“œ + ë…¸ì´ì¦ˆ)
    base_values = 100 + np.arange(720) * 0.1 + np.random.normal(0, 5, 720)

    # ì¸ìœ„ì  ì´ìƒì¹˜ ì‚½ì… (10ê°œ)
    anomaly_indices = [50, 120, 180, 250, 320, 400, 480, 550, 620, 680]
    for idx in anomaly_indices:
        base_values[idx] += np.random.choice([-1, 1]) * np.random.uniform(20, 30)

    return pd.DataFrame({
        'timestamp': dates,
        'metric': 'test_cpu_usage',
        'value': base_values
    })

@pytest.fixture
def large_dataset():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìƒì„± (10ë§Œ í¬ì¸íŠ¸)"""
    np.random.seed(123)

    # 10ë§Œ í¬ì¸íŠ¸ (ì•½ 11ë…„ê°„ ì‹œê°„ë‹¹ ë°ì´í„°)
    dates = pd.date_range(start='2014-01-01', periods=100000, freq='H')

    # ë³µì¡í•œ íŒ¨í„´ì˜ ì‹œê³„ì—´
    trend = np.arange(100000) * 0.01
    seasonal = 10 * np.sin(2 * np.pi * np.arange(100000) / (24 * 365.25))  # ì—°ê°„ ì£¼ê¸°
    noise = np.random.normal(0, 2, 100000)

    values = 500 + trend + seasonal + noise

    # ëŒ€ëŸ‰ ì´ìƒì¹˜ ì‚½ì… (1000ê°œ, 1%)
    anomaly_indices = np.random.choice(100000, 1000, replace=False)
    for idx in anomaly_indices:
        values[idx] += np.random.choice([-1, 1]) * np.random.uniform(15, 25)

    return pd.DataFrame({
        'timestamp': dates,
        'metric': 'test_large_dataset',
        'value': values
    })

@pytest.fixture
def api_client():
    """FastAPI í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸"""
    return TestClient(app)

@pytest.fixture
def script_path():
    """ì´ìƒíƒì§€ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ"""
    return project_root / "scripts" / "anomaly_detect.py"

# ================================================================
# ì´ìƒíƒì§€ ì—”ì§„ í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

class TestAnomalyDetectorCore:
    """ì´ìƒíƒì§€ ì—”ì§„ í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_detector_initialization(self):
        """ì´ìƒíƒì§€ ì—”ì§„ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        detector = AnomalyDetector(
            window_size=14,
            threshold=2.5,
            forecast_days=10,
            ewma_alpha=0.2
        )

        assert detector.window_size == 14
        assert detector.threshold == 2.5
        assert detector.forecast_days == 10
        assert detector.ewma_alpha == 0.2
        assert detector.metrics_data == {}
        assert detector.anomalies == {}
        assert detector.forecasts == {}

    def test_metrics_json_parsing(self, anomaly_detector):
        """ë©”íŠ¸ë¦­ JSON ë°ì´í„° íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        # ë‹¤ì–‘í•œ JSON í˜•ì‹ í…ŒìŠ¤íŠ¸
        test_cases = [
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœ JSON
            {
                "data": [
                    {"timestamp": "2024-01-01T00:00:00", "cpu_usage": 45.2, "memory_usage": 60.5},
                    {"timestamp": "2024-01-01T01:00:00", "cpu_usage": 48.1, "memory_usage": 62.3}
                ],
                "expected_records": 4  # 2ê°œ timestamp Ã— 2ê°œ ë©”íŠ¸ë¦­
            },
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœ JSON
            {
                "data": {
                    "cpu_metric": {
                        "2024-01-01": 45.2,
                        "2024-01-02": 48.1
                    }
                },
                "expected_records": 2
            }
        ]

        for case in test_cases:
            df = anomaly_detector._parse_metrics_json(case["data"], "test_file")
            assert df is not None
            assert len(df) == case["expected_records"]
            assert 'timestamp' in df.columns
            assert 'metric' in df.columns
            assert 'value' in df.columns

    def test_data_preprocessing(self, anomaly_detector, sample_timeseries_data):
        """ë°ì´í„° ì „ì²˜ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •
        anomaly_detector.metrics_data = {"test_source": sample_timeseries_data}

        # ì „ì²˜ë¦¬ ì‹¤í–‰
        processed_data = anomaly_detector.preprocess_data()

        assert len(processed_data) > 0

        for metric_name, df in processed_data.items():
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['timestamp', 'value', 'ewma', 'rolling_mean', 'rolling_std', 'z_score']
            for col in required_cols:
                assert col in df.columns, f"ì»¬ëŸ¼ {col}ì´ ëˆ„ë½ë¨"

            # ë°ì´í„° í’ˆì§ˆ í™•ì¸
            assert not df['value'].isna().any(), "ì „ì²˜ë¦¬ í›„ì—ë„ ëˆ„ë½ê°’ì´ ì¡´ì¬í•¨"
            assert not df['ewma'].isna().any(), "EWMA ê³„ì‚° ì‹¤íŒ¨"
            assert not df['z_score'].isna().any(), "Z-score ê³„ì‚° ì‹¤íŒ¨"

            # EWMAê°€ ì‹¤ì œ ê°’ë³´ë‹¤ ìŠ¤ë¬´ë”©ë˜ì—ˆëŠ”ì§€ í™•ì¸
            value_std = df['value'].std()
            ewma_std = df['ewma'].std()
            assert ewma_std <= value_std, "EWMAê°€ ì¶©ë¶„íˆ ìŠ¤ë¬´ë”©ë˜ì§€ ì•ŠìŒ"

    @pytest.mark.parametrize("window_size,threshold,expected_min_anomalies", [
        (5, 2.0, 15),   # ë‚®ì€ ì„ê³„ì¹˜ â†’ ë§ì€ ì´ìƒì¹˜
        (7, 3.0, 8),    # ê¸°ë³¸ ì„¤ì •
        (10, 4.0, 3),   # ë†’ì€ ì„ê³„ì¹˜ â†’ ì ì€ ì´ìƒì¹˜
    ])
    def test_anomaly_detection_parameters(self, sample_timeseries_data, window_size, threshold, expected_min_anomalies):
        """ì´ìƒíƒì§€ íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ê²°ê³¼ ê²€ì¦"""
        detector = AnomalyDetector(
            window_size=window_size,
            threshold=threshold,
            forecast_days=7
        )

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì • ë° ì „ì²˜ë¦¬
        detector.metrics_data = {"test_source": sample_timeseries_data}
        processed_data = detector.preprocess_data()

        # ì´ìƒíƒì§€ ì‹¤í–‰
        anomalies = detector.detect_anomalies(processed_data)

        # ê²°ê³¼ ê²€ì¦
        total_anomalies = sum(len(anomaly_list) for anomaly_list in anomalies.values())

        # ì„ê³„ì¹˜ê°€ ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ì´ìƒì¹˜ê°€ íƒì§€ë˜ì–´ì•¼ í•¨
        if threshold <= 2.5:
            assert total_anomalies >= expected_min_anomalies, f"ì„ê³„ì¹˜ {threshold}ì—ì„œ ì´ìƒì¹˜ê°€ ë„ˆë¬´ ì ìŒ: {total_anomalies}"

        # ëª¨ë“  ì´ìƒì¹˜ì˜ Z-score ì ˆëŒ“ê°’ì´ ì„ê³„ì¹˜ë¥¼ ì´ˆê³¼í•´ì•¼ í•¨
        for metric_name, anomaly_list in anomalies.items():
            for anomaly in anomaly_list:
                assert abs(anomaly['z_score']) > threshold, f"Z-score {anomaly['z_score']}ì´ ì„ê³„ì¹˜ {threshold}ë¥¼ ì´ˆê³¼í•˜ì§€ ì•ŠìŒ"

    def test_anomaly_severity_classification(self, anomaly_detector):
        """ì´ìƒì¹˜ ì‹¬ê°ë„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            (2.5, 'low'),
            (3.5, 'medium'),
            (4.2, 'high'),
            (5.5, 'critical')
        ]

        for z_score, expected_severity in test_cases:
            severity = anomaly_detector._classify_anomaly_severity(z_score)
            assert severity == expected_severity, f"Z-score {z_score}ì˜ ì‹¬ê°ë„ ë¶„ë¥˜ê°€ ì˜ëª»ë¨: {severity} (ì˜ˆìƒ: {expected_severity})"

    def test_forecast_generation(self, anomaly_detector, sample_timeseries_data):
        """ì˜ˆì¸¡ ìƒì„± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì • ë° ì „ì²˜ë¦¬
        anomaly_detector.metrics_data = {"test_source": sample_timeseries_data}
        processed_data = anomaly_detector.preprocess_data()

        # ì˜ˆì¸¡ ìƒì„±
        forecasts = anomaly_detector.generate_forecasts(processed_data)

        assert len(forecasts) > 0, "ì˜ˆì¸¡ ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ"

        for metric_name, forecast_info in forecasts.items():
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['forecast_points', 'trend_direction', 'trend_strength', 'model_accuracy']
            for field in required_fields:
                assert field in forecast_info, f"ì˜ˆì¸¡ ê²°ê³¼ì— {field} í•„ë“œê°€ ëˆ„ë½ë¨"

            # ì˜ˆì¸¡ í¬ì¸íŠ¸ ê°œìˆ˜ í™•ì¸
            forecast_points = forecast_info['forecast_points']
            assert len(forecast_points) == anomaly_detector.forecast_days, "ì˜ˆì¸¡ ê¸°ê°„ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ"

            # ì˜ˆì¸¡ í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸
            for point in forecast_points:
                required_point_fields = ['date', 'predicted_value', 'lower_bound', 'upper_bound', 'confidence']
                for field in required_point_fields:
                    assert field in point, f"ì˜ˆì¸¡ í¬ì¸íŠ¸ì— {field} í•„ë“œê°€ ëˆ„ë½ë¨"

                # ì‹ ë¢°êµ¬ê°„ ê²€ì¦
                assert point['lower_bound'] <= point['predicted_value'] <= point['upper_bound'], "ì‹ ë¢°êµ¬ê°„ì´ ì˜ëª»ë¨"
                assert 0 <= point['confidence'] <= 1, "ì‹ ë¢°ë„ê°€ 0-1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨"

            # ëª¨ë¸ ì •í™•ë„ ê²€ì¦
            assert 0 <= forecast_info['model_accuracy'] <= 1, "ëª¨ë¸ ì •í™•ë„ê°€ 0-1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨"

    def test_trend_direction_detection(self, anomaly_detector):
        """ì¶”ì„¸ ë°©í–¥ íƒì§€ í…ŒìŠ¤íŠ¸"""
        # ì¦ê°€ ì¶”ì„¸ ë°ì´í„°
        increasing_data = pd.DataFrame({
            'timestamp': pd.date_range('2024-01-01', periods=100, freq='H'),
            'metric': 'increasing_test',
            'value': np.arange(100) * 2 + np.random.normal(0, 1, 100)  # ëª…í™•í•œ ì¦ê°€ ì¶”ì„¸
        })

        # ê°ì†Œ ì¶”ì„¸ ë°ì´í„°
        decreasing_data = pd.DataFrame({
            'timestamp': pd.date_range('2024-01-01', periods=100, freq='H'),
            'metric': 'decreasing_test',
            'value': 100 - np.arange(100) * 1.5 + np.random.normal(0, 1, 100)  # ëª…í™•í•œ ê°ì†Œ ì¶”ì„¸
        })

        for data, expected_trend in [(increasing_data, 'increasing'), (decreasing_data, 'decreasing')]:
            anomaly_detector.metrics_data = {"test_source": data}
            processed_data = anomaly_detector.preprocess_data()
            forecasts = anomaly_detector.generate_forecasts(processed_data)

            assert len(forecasts) > 0

            for metric_name, forecast_info in forecasts.items():
                assert forecast_info['trend_direction'] == expected_trend, \
                    f"ì¶”ì„¸ ë°©í–¥ íƒì§€ ì‹¤íŒ¨: {forecast_info['trend_direction']} (ì˜ˆìƒ: {expected_trend})"

    def test_risk_level_calculation(self, anomaly_detector, sample_timeseries_data):
        """ìœ„í—˜ë„ ìˆ˜ì¤€ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        anomaly_detector.metrics_data = {"test_source": sample_timeseries_data}
        processed_data = anomaly_detector.preprocess_data()
        anomalies = anomaly_detector.detect_anomalies(processed_data)
        forecasts = anomaly_detector.generate_forecasts(processed_data)
        risk_levels = anomaly_detector.calculate_risk_levels()

        assert len(risk_levels) > 0, "ìœ„í—˜ë„ ìˆ˜ì¤€ì´ ê³„ì‚°ë˜ì§€ ì•ŠìŒ"

        valid_risk_levels = ['low', 'medium', 'high', 'critical']
        for metric_name, risk_level in risk_levels.items():
            assert risk_level in valid_risk_levels, f"ì˜ëª»ëœ ìœ„í—˜ë„ ìˆ˜ì¤€: {risk_level}"

# ================================================================
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

class TestAnomalyDetectorPerformance:
    """ì´ìƒíƒì§€ ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_large_dataset_processing(self, large_dataset):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (10ë§Œ í¬ì¸íŠ¸, 5ì´ˆ ì´ë‚´)"""
        detector = AnomalyDetector(
            window_size=7,
            threshold=3.0,
            forecast_days=7
        )

        start_time = time.time()

        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
        detector.metrics_data = {"large_dataset": large_dataset}
        processed_data = detector.preprocess_data()
        anomalies = detector.detect_anomalies(processed_data)

        processing_time = time.time() - start_time

        # ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­: 10ë§Œ í¬ì¸íŠ¸ë¥¼ 5ì´ˆ ì´ë‚´ì— ì²˜ë¦¬
        assert processing_time < 5.0, f"ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼: {processing_time:.2f}ì´ˆ"

        # ê²°ê³¼ í’ˆì§ˆ í™•ì¸
        assert len(processed_data) > 0, "ì „ì²˜ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ"
        assert len(anomalies) > 0, "ì´ìƒì¹˜ê°€ ì „í˜€ íƒì§€ë˜ì§€ ì•ŠìŒ"

        total_anomalies = sum(len(anomaly_list) for anomaly_list in anomalies.values())
        # 1% ì •ë„ì˜ ì´ìƒì¹˜ê°€ íƒì§€ë˜ì–´ì•¼ í•¨ (ëŒ€ëµ 500-1500ê°œ)
        assert 200 <= total_anomalies <= 2000, f"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì´ìƒì¹˜ ê°œìˆ˜: {total_anomalies}"

    def test_memory_efficiency(self, large_dataset):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        import psutil
        import os

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        detector = AnomalyDetector()
        detector.metrics_data = {"large_dataset": large_dataset}
        processed_data = detector.preprocess_data()
        anomalies = detector.detect_anomalies(processed_data)

        peak_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = peak_memory - initial_memory

        # 10ë§Œ í¬ì¸íŠ¸ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ 500MBë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šì•„ì•¼ í•¨
        assert memory_increase < 500, f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼: {memory_increase:.2f}MB"

    @pytest.mark.parametrize("data_size", [1000, 5000, 10000])
    def test_scalability(self, data_size):
        """í™•ì¥ì„± í…ŒìŠ¤íŠ¸ - ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€ìœ¨"""
        np.random.seed(42)

        # ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ ìƒì„±
        dates = pd.date_range('2024-01-01', periods=data_size, freq='H')
        values = 100 + np.arange(data_size) * 0.01 + np.random.normal(0, 5, data_size)

        test_data = pd.DataFrame({
            'timestamp': dates,
            'metric': f'scalability_test_{data_size}',
            'value': values
        })

        detector = AnomalyDetector()

        start_time = time.time()
        detector.metrics_data = {"test_data": test_data}
        processed_data = detector.preprocess_data()
        anomalies = detector.detect_anomalies(processed_data)
        processing_time = time.time() - start_time

        # ì²˜ë¦¬ ì‹œê°„ì´ ë°ì´í„° í¬ê¸°ì— ë¹„ë¡€í•˜ì—¬ í•©ë¦¬ì ìœ¼ë¡œ ì¦ê°€í•´ì•¼ í•¨
        # 1000 í¬ì¸íŠ¸ë‹¹ ëŒ€ëµ 0.1ì´ˆ ì´í•˜
        expected_max_time = data_size / 1000 * 0.1
        assert processing_time < expected_max_time, f"ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ ({data_size} í¬ì¸íŠ¸): {processing_time:.3f}ì´ˆ"

# ================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

class TestAnomalyDetectionScript:
    """ì´ìƒíƒì§€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_script_basic_execution(self, script_path, tmp_path):
        """ìŠ¤í¬ë¦½íŠ¸ ê¸°ë³¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        if not script_path.exists():
            pytest.skip(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìŒ: {script_path}")

        try:
            result = subprocess.run(
                [sys.executable, str(script_path), "--dry-run", "--days", "7"],
                capture_output=True,
                text=True,
                timeout=30,
                cwd=tmp_path
            )

            # ìŠ¤í¬ë¦½íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
            assert result.returncode == 0, f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"

            # ì¶œë ¥ì— ë¶„ì„ ê´€ë ¨ ë¡œê·¸ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨
            output = result.stdout + result.stderr
            assert "ì´ìƒíƒì§€" in output or "anomaly" in output.lower(), "ì´ìƒíƒì§€ ê´€ë ¨ ë¡œê·¸ê°€ ì—†ìŒ"

        except subprocess.TimeoutExpired:
            pytest.fail("ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ì´ 30ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    @pytest.mark.parametrize("output_format", ["json", "markdown"])
    def test_script_output_formats(self, script_path, tmp_path, output_format):
        """ìŠ¤í¬ë¦½íŠ¸ ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸"""
        if not script_path.exists():
            pytest.skip(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìŒ: {script_path}")

        output_file = tmp_path / f"test_output.{output_format}"

        try:
            cmd = [
                sys.executable, str(script_path),
                "--dry-run",
                "--days", "7",
                f"--{output_format}",
                "--output", str(output_file)
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30,
                cwd=tmp_path
            )

            assert result.returncode == 0, f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"
            assert output_file.exists(), f"ì¶œë ¥ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ: {output_file}"

            # íŒŒì¼ ë‚´ìš© ê²€ì¦
            content = output_file.read_text(encoding='utf-8')
            assert len(content) > 0, "ì¶œë ¥ íŒŒì¼ì´ ë¹„ì–´ìˆìŒ"

            if output_format == "json":
                # JSON íŒŒì‹± ê°€ëŠ¥ì„± í™•ì¸
                data = json.loads(content)
                assert isinstance(data, dict), "JSON ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜"
            elif output_format == "markdown":
                # Markdown í—¤ë” í™•ì¸
                assert "#" in content, "Markdown í—¤ë”ê°€ ì—†ìŒ"
                assert "ì´ìƒíƒì§€" in content or "anomaly" in content.lower(), "ì´ìƒíƒì§€ ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŒ"

        except subprocess.TimeoutExpired:
            pytest.fail(f"{output_format} í˜•ì‹ í…ŒìŠ¤íŠ¸ê°€ 30ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    @pytest.mark.parametrize("threshold", [2.0, 3.0, 4.0])
    def test_script_threshold_parameter(self, script_path, tmp_path, threshold):
        """ìŠ¤í¬ë¦½íŠ¸ ì„ê³„ì¹˜ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸"""
        if not script_path.exists():
            pytest.skip(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìŒ: {script_path}")

        try:
            result = subprocess.run(
                [sys.executable, str(script_path), "--dry-run", "--threshold", str(threshold)],
                capture_output=True,
                text=True,
                timeout=30,
                cwd=tmp_path
            )

            assert result.returncode == 0, f"ì„ê³„ì¹˜ {threshold} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.stderr}"

            # ë¡œê·¸ì— ì„¤ì •ëœ ì„ê³„ì¹˜ê°€ í‘œì‹œë˜ì–´ì•¼ í•¨
            output = result.stderr
            assert f"threshold={threshold}" in output or f"ì„ê³„ì¹˜: {threshold}" in output, \
                f"ì„ê³„ì¹˜ {threshold}ì´ ë¡œê·¸ì— í‘œì‹œë˜ì§€ ì•ŠìŒ"

        except subprocess.TimeoutExpired:
            pytest.fail(f"ì„ê³„ì¹˜ {threshold} í…ŒìŠ¤íŠ¸ê°€ 30ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    def test_script_invalid_parameters(self, script_path, tmp_path):
        """ìŠ¤í¬ë¦½íŠ¸ ì˜ëª»ëœ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸"""
        if not script_path.exists():
            pytest.skip(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìŒ: {script_path}")

        invalid_cases = [
            ["--threshold", "0.5"],  # ë„ˆë¬´ ë‚®ì€ ì„ê³„ì¹˜
            ["--threshold", "10.0"], # ë„ˆë¬´ ë†’ì€ ì„ê³„ì¹˜
            ["--window", "1"],       # ë„ˆë¬´ ì‘ì€ ìœˆë„ìš°
            ["--days", "0"],         # ì˜ëª»ëœ ì¼ìˆ˜
            ["--forecast", "0"]      # ì˜ëª»ëœ ì˜ˆì¸¡ ê¸°ê°„
        ]

        for invalid_params in invalid_cases:
            try:
                result = subprocess.run(
                    [sys.executable, str(script_path), "--dry-run"] + invalid_params,
                    capture_output=True,
                    text=True,
                    timeout=15,
                    cwd=tmp_path
                )

                # ì¼ë¶€ ì˜ëª»ëœ íŒŒë¼ë¯¸í„°ëŠ” ì—ëŸ¬ë¡œ ì²˜ë¦¬ë˜ê±°ë‚˜ ê²½ê³ ê°€ í‘œì‹œë˜ì–´ì•¼ í•¨
                # (êµ¬í˜„ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë„ˆë¬´ ì—„ê²©í•˜ê²Œ í…ŒìŠ¤íŠ¸í•˜ì§€ ì•ŠìŒ)

            except subprocess.TimeoutExpired:
                pytest.fail(f"ì˜ëª»ëœ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸ê°€ 15ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {invalid_params}")

# ================================================================
# API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

class TestAnomalyAPI:
    """ì´ìƒíƒì§€ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_health_endpoint(self, api_client):
        """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        response = api_client.get("/api/v1/anomaly/health")

        assert response.status_code == 200
        data = response.json()

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['status', 'data_sources_available', 'cache_hit_rate', 'avg_response_time_ms']
        for field in required_fields:
            assert field in data, f"í—¬ìŠ¤ì²´í¬ ì‘ë‹µì— {field} í•„ë“œê°€ ëˆ„ë½ë¨"

        # ìƒíƒœ ê°’ ê²€ì¦
        valid_statuses = ['healthy', 'degraded', 'unhealthy']
        assert data['status'] in valid_statuses, f"ì˜ëª»ëœ ìƒíƒœ ê°’: {data['status']}"

    def test_summary_endpoint_without_auth(self, api_client):
        """ì¸ì¦ ì—†ì´ ìš”ì•½ ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ (403 ì˜ˆìƒ)"""
        response = api_client.get("/api/v1/anomaly/summary")

        # ì¸ì¦ì´ í•„ìš”í•œ ì—”ë“œí¬ì¸íŠ¸ì´ë¯€ë¡œ 403 ë˜ëŠ” 401ì´ ë°˜í™˜ë˜ì–´ì•¼ í•¨
        assert response.status_code in [401, 403], f"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìƒíƒœ ì½”ë“œ: {response.status_code}"

    def test_timeseries_endpoint_with_parameters(self, api_client):
        """ì‹œê³„ì—´ ì—”ë“œí¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸"""
        # ì¸ì¦ í—¤ë” ì—†ì´ í…ŒìŠ¤íŠ¸ (403 ì˜ˆìƒ)
        response = api_client.get("/api/v1/anomaly/timeseries?days=7&metric=cpu")
        assert response.status_code in [401, 403]

        # ì˜ëª»ëœ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸
        response = api_client.get("/api/v1/anomaly/timeseries?days=invalid")
        assert response.status_code in [400, 401, 403, 422]  # íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ ë˜ëŠ” ì¸ì¦ ì˜¤ë¥˜

    def test_forecast_endpoint_parameters(self, api_client):
        """ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸"""
        # ìœ íš¨í•œ íŒŒë¼ë¯¸í„° (ì¸ì¦ ì—†ì´ëŠ” 403 ì˜ˆìƒ)
        response = api_client.get("/api/v1/anomaly/forecast?forecast_days=7")
        assert response.status_code in [401, 403]

        # ì˜ëª»ëœ íŒŒë¼ë¯¸í„°
        response = api_client.get("/api/v1/anomaly/forecast?forecast_days=100")  # ë„ˆë¬´ í° ê°’
        assert response.status_code in [400, 401, 403, 422]

    def test_run_endpoint_post_method(self, api_client):
        """ë¶„ì„ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸ POST ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""
        request_data = {
            "days": 30,
            "threshold": 3.0,
            "window_size": 7,
            "forecast_days": 7,
            "force_refresh": True
        }

        response = api_client.post(
            "/api/v1/anomaly/run",
            json=request_data
        )

        # ì¸ì¦ì´ í•„ìš”í•˜ë¯€ë¡œ 401 ë˜ëŠ” 403ì´ ì˜ˆìƒë¨
        assert response.status_code in [401, 403], f"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìƒíƒœ ì½”ë“œ: {response.status_code}"

    def test_report_markdown_endpoint(self, api_client):
        """Markdown ë¦¬í¬íŠ¸ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        response = api_client.get("/api/v1/anomaly/report.md?days=7")

        # ì¸ì¦ì´ í•„ìš”í•˜ë¯€ë¡œ 401 ë˜ëŠ” 403ì´ ì˜ˆìƒë¨
        assert response.status_code in [401, 403]

    def test_api_error_handling(self, api_client):
        """API ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸
        response = api_client.get("/api/v1/anomaly/nonexistent")
        assert response.status_code == 404

        # ì˜ëª»ëœ HTTP ë©”ì„œë“œ
        response = api_client.delete("/api/v1/anomaly/summary")
        assert response.status_code in [405, 401, 403]  # Method Not Allowed ë˜ëŠ” ì¸ì¦ ì˜¤ë¥˜

# ================================================================
# í†µí•© í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

class TestAnomalyIntegration:
    """ì´ìƒíƒì§€ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_end_to_end_workflow(self, sample_timeseries_data):
        """ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸"""
        # 1. ì´ìƒíƒì§€ ì—”ì§„ ì´ˆê¸°í™”
        detector = AnomalyDetector(
            window_size=7,
            threshold=3.0,
            forecast_days=7
        )

        # 2. ë°ì´í„° ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜)
        detector.metrics_data = {"integration_test": sample_timeseries_data}

        # 3. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        processed_data = detector.preprocess_data()
        assert len(processed_data) > 0, "ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨"

        anomalies = detector.detect_anomalies(processed_data)
        assert len(anomalies) > 0, "ì´ìƒì¹˜ íƒì§€ ì‹¤íŒ¨"

        forecasts = detector.generate_forecasts(processed_data)
        assert len(forecasts) > 0, "ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨"

        risk_levels = detector.calculate_risk_levels()
        assert len(risk_levels) > 0, "ìœ„í—˜ë„ ê³„ì‚° ì‹¤íŒ¨"

        # 4. ë¦¬í¬íŠ¸ ìƒì„±
        json_report = detector.generate_report('json')
        assert len(json_report) > 0, "JSON ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"

        # JSON íŒŒì‹± ê°€ëŠ¥ì„± í™•ì¸
        report_data = json.loads(json_report)
        assert 'metadata' in report_data, "ë¦¬í¬íŠ¸ ë©”íƒ€ë°ì´í„° ëˆ„ë½"
        assert 'summary' in report_data, "ë¦¬í¬íŠ¸ ìš”ì•½ ëˆ„ë½"

        markdown_report = detector.generate_report('markdown')
        assert len(markdown_report) > 0, "Markdown ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"
        assert '#' in markdown_report, "Markdown í˜•ì‹ì´ ì•„ë‹˜"

    def test_concurrent_detection(self, sample_timeseries_data):
        """ë™ì‹œ ì´ìƒíƒì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        import threading
        import queue

        results = queue.Queue()

        def run_detection(thread_id):
            detector = AnomalyDetector()
            detector.metrics_data = {f"thread_{thread_id}": sample_timeseries_data}

            try:
                processed_data = detector.preprocess_data()
                anomalies = detector.detect_anomalies(processed_data)
                results.put((thread_id, True, len(anomalies)))
            except Exception as e:
                results.put((thread_id, False, str(e)))

        # 5ê°œì˜ ë™ì‹œ ìŠ¤ë ˆë“œë¡œ ì´ìƒíƒì§€ ì‹¤í–‰
        threads = []
        for i in range(5):
            thread = threading.Thread(target=run_detection, args=(i,))
            threads.append(thread)
            thread.start()

        # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
        for thread in threads:
            thread.join(timeout=10)

        # ê²°ê³¼ ê²€ì¦
        successful_detections = 0
        while not results.empty():
            thread_id, success, result = results.get()
            if success:
                successful_detections += 1
                assert result > 0, f"ìŠ¤ë ˆë“œ {thread_id}ì—ì„œ ì´ìƒì¹˜ê°€ íƒì§€ë˜ì§€ ì•ŠìŒ"
            else:
                pytest.fail(f"ìŠ¤ë ˆë“œ {thread_id}ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {result}")

        assert successful_detections == 5, f"ì„±ê³µí•œ íƒì§€ ìˆ˜ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„: {successful_detections}"

    def test_data_consistency(self, sample_timeseries_data):
        """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ - ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ ë™ì¼í•œ ê²°ê³¼"""
        detector1 = AnomalyDetector(window_size=7, threshold=3.0, forecast_days=7)
        detector2 = AnomalyDetector(window_size=7, threshold=3.0, forecast_days=7)

        # ë™ì¼í•œ ë°ì´í„°ë¡œ ë‘ ë²ˆ ì‹¤í–‰
        for detector in [detector1, detector2]:
            detector.metrics_data = {"consistency_test": sample_timeseries_data.copy()}

        # ì²« ë²ˆì§¸ ì‹¤í–‰
        processed_data1 = detector1.preprocess_data()
        anomalies1 = detector1.detect_anomalies(processed_data1)

        # ë‘ ë²ˆì§¸ ì‹¤í–‰
        processed_data2 = detector2.preprocess_data()
        anomalies2 = detector2.detect_anomalies(processed_data2)

        # ê²°ê³¼ ë¹„êµ
        assert len(anomalies1) == len(anomalies2), "ì´ìƒì¹˜ íƒì§€ ê²°ê³¼ê°€ ì¼ê´€ë˜ì§€ ì•ŠìŒ"

        for metric_name in anomalies1:
            if metric_name in anomalies2:
                anomaly_count1 = len(anomalies1[metric_name])
                anomaly_count2 = len(anomalies2[metric_name])
                assert anomaly_count1 == anomaly_count2, f"ë©”íŠ¸ë¦­ {metric_name}ì˜ ì´ìƒì¹˜ ê°œìˆ˜ê°€ ì¼ê´€ë˜ì§€ ì•ŠìŒ"

    def test_edge_cases(self):
        """ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸"""
        detector = AnomalyDetector()

        # ë¹ˆ ë°ì´í„°
        detector.metrics_data = {}
        processed_data = detector.preprocess_data()
        assert len(processed_data) == 0, "ë¹ˆ ë°ì´í„° ì²˜ë¦¬ ê²°ê³¼ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„"

        # ë‹¨ì¼ í¬ì¸íŠ¸ ë°ì´í„°
        single_point_data = pd.DataFrame({
            'timestamp': [pd.Timestamp('2024-01-01')],
            'metric': ['single_point'],
            'value': [100.0]
        })

        detector.metrics_data = {"single_point": single_point_data}
        processed_data = detector.preprocess_data()
        # ë‹¨ì¼ í¬ì¸íŠ¸ëŠ” ìœˆë„ìš° í¬ê¸° ë¶€ì¡±ìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ ì•Šì•„ì•¼ í•¨
        assert len(processed_data) == 0, "ë‹¨ì¼ í¬ì¸íŠ¸ ë°ì´í„°ê°€ ì˜ëª» ì²˜ë¦¬ë¨"

        # ëª¨ë“  ê°’ì´ ë™ì¼í•œ ë°ì´í„°
        constant_data = pd.DataFrame({
            'timestamp': pd.date_range('2024-01-01', periods=100, freq='H'),
            'metric': ['constant_test'] * 100,
            'value': [50.0] * 100
        })

        detector.metrics_data = {"constant_test": constant_data}
        processed_data = detector.preprocess_data()

        if len(processed_data) > 0:
            anomalies = detector.detect_anomalies(processed_data)
            # ìƒìˆ˜ ë°ì´í„°ì—ì„œëŠ” ì´ìƒì¹˜ê°€ íƒì§€ë˜ì§€ ì•Šì•„ì•¼ í•¨
            total_anomalies = sum(len(anomaly_list) for anomaly_list in anomalies.values())
            assert total_anomalies == 0, f"ìƒìˆ˜ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ê°€ íƒì§€ë¨: {total_anomalies}ê°œ"

# ================================================================
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œ ì¶”ê°€ ì •ë³´ ì¶œë ¥ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
# ================================================================

def pytest_runtest_makereport(item, call):
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ ì¶œë ¥"""
    if call.when == "call":
        if call.excinfo is not None:
            # í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ í•œêµ­ì–´ ë©”ì‹œì§€ ì¶œë ¥
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {item.name}")
            print(f"   ì˜¤ë¥˜ ë‚´ìš©: {call.excinfo.value}")
        else:
            # í…ŒìŠ¤íŠ¸ ì„±ê³µ ì‹œ ê°„ë‹¨í•œ ë©”ì‹œì§€
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: {item.name}")

# í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ì‹¤í–‰ ì‹œ í™˜ê²½ ì •ë³´ ì¶œë ¥
if __name__ == "__main__":
    print("ğŸ” ì´ìƒíƒì§€ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸")
    print(f"ğŸ“‚ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"ğŸ Python ë²„ì „: {sys.version}")
    print("=" * 60)

    # pytest ì‹¤í–‰
    pytest.main([__file__, "-v", "--tb=short"])