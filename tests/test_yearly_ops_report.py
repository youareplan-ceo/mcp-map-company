#!/usr/bin/env python3
"""
ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì£¼ì„ í¬í•¨)
Yearly Operations Report System Tests

ì´ íŒŒì¼ì€ scripts/yearly_ops_report.shì™€ mcp/utils/notifier.pyì˜
ì—°ê°„ ë¦¬í¬íŠ¸ ìƒì„± ë° ì•Œë¦¼ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ í•­ëª©:
1. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê²€ì¦ (ë„ì›€ë§, dry-run, JSON ëª¨ë“œ)
2. ì—°ê°„ ì ìˆ˜ ê³„ì‚° ë° ë“±ê¸‰ íŒì • ê²€ì¦
3. ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™ í™•ì¸
4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (1ë…„ ë°ì´í„° 60ì´ˆ ì´ë‚´ ì²˜ë¦¬)
"""

import pytest
import json
import subprocess
import tempfile
import asyncio
import os
import time
from pathlib import Path
from datetime import datetime, timedelta
from unittest.mock import patch, Mock, MagicMock, AsyncMock
import sys

# mcp ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from mcp.utils.notifier import send_yearly_ops_report, notify_yearly_report, NotificationLevel
except ImportError:
    pytest.skip("notifier ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", allow_module_level=True)


class TestYearlyOpsReportScript:
    """ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸ ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.fixture
    def script_path(self):
        """yearly_ops_report.sh ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ"""
        script_path = Path(__file__).parent.parent / "scripts" / "yearly_ops_report.sh"
        assert script_path.exists(), f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {script_path}"
        return str(script_path)

    @pytest.fixture
    def temp_project_structure(self):
        """ì„ì‹œ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±"""
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # í•„ìš”í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
            (temp_path / "reports" / "yearly").mkdir(parents=True, exist_ok=True)
            (temp_path / "reports" / "monthly").mkdir(parents=True, exist_ok=True)
            (temp_path / "reports" / "ci_reports").mkdir(parents=True, exist_ok=True)
            (temp_path / "logs").mkdir(parents=True, exist_ok=True)

            # ìƒ˜í”Œ ë³´ì•ˆ ë¡œê·¸ ìƒì„±
            security_log = temp_path / "logs" / "security.log"
            with open(security_log, 'w', encoding='utf-8') as f:
                f.write("2024-01-15 10:30:00 [INFO] IP_BLOCKED: 192.168.1.100\n")
                f.write("2024-02-20 14:25:00 [WARN] RATE_LIMIT_EXCEEDED: api/v1/auth\n")
                f.write("2024-03-10 09:15:00 [INFO] IP_WHITELISTED: 10.0.0.5\n")

            # ìƒ˜í”Œ ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
            for month in range(1, 13):
                month_str = f"2024-{month:02d}"
                monthly_report = temp_path / "reports" / "monthly" / f"monthly-report-{month_str}.json"
                with open(monthly_report, 'w', encoding='utf-8') as f:
                    json.dump({
                        "report_metadata": {"period_end": f"{month_str}-21"},
                        "backup_operations": {
                            "successful_backups": 28 + (month % 3),
                            "failed_backups": 2 - (month % 3),
                            "cleanup_operations": 8
                        }
                    }, f, ensure_ascii=False, indent=2)

            # ìƒ˜í”Œ CI ë¦¬í¬íŠ¸ ìƒì„±
            for i in range(10):
                ci_report = temp_path / "reports" / "ci_reports" / f"2024-01-{15 + i:02d}-build-{100 + i}.json"
                with open(ci_report, 'w', encoding='utf-8') as f:
                    json.dump({
                        "status": "success" if i % 4 != 0 else "failed",
                        "execution_time": 200 + (i * 10),
                        "coverage": {"percentage": 80 + (i % 10)},
                        "timestamp": f"2024-01-{15 + i:02d}T10:30:00Z"
                    }, f, ensure_ascii=False, indent=2)

            yield temp_path

    def test_script_help_option(self, script_path):
        """ë„ì›€ë§ ì˜µì…˜ í…ŒìŠ¤íŠ¸"""
        try:
            result = subprocess.run(
                [script_path, "--help"],
                capture_output=True,
                text=True,
                timeout=30
            )

            assert result.returncode == 0, f"ë„ì›€ë§ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"
            assert "ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸ ìë™í™” ìŠ¤í¬ë¦½íŠ¸" in result.stdout
            assert "--dry-run" in result.stdout
            assert "--json" in result.stdout
            assert "--verbose" in result.stdout

        except subprocess.TimeoutExpired:
            pytest.fail("ë„ì›€ë§ ì¶œë ¥ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
        except Exception as e:
            pytest.fail(f"ë„ì›€ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    def test_script_dry_run_mode(self, script_path, temp_project_structure):
        """ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
            env = os.environ.copy()
            env['PROJECT_ROOT'] = str(temp_project_structure)

            result = subprocess.run(
                [script_path, "--dry-run", "--verbose"],
                capture_output=True,
                text=True,
                timeout=60,
                cwd=str(temp_project_structure),
                env=env
            )

            # ìŠ¤í¬ë¦½íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
            assert result.returncode == 0, f"Dry-run ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"

            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ë©”ì‹œì§€ í™•ì¸
            assert "ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ" in result.stderr or "DRY RUN" in result.stderr
            assert "ì—°ê°„ ë¦¬í¬íŠ¸ ìƒì„±" in result.stderr

            # ì‹¤ì œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
            yearly_reports_dir = temp_project_structure / "reports" / "yearly"
            report_files = list(yearly_reports_dir.glob("*.md")) + list(yearly_reports_dir.glob("*.json"))
            assert len(report_files) == 0, "Dry-run ëª¨ë“œì—ì„œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"

        except subprocess.TimeoutExpired:
            pytest.fail("Dry-run ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ)")
        except Exception as e:
            pytest.fail(f"Dry-run í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    def test_script_json_output_mode(self, script_path, temp_project_structure):
        """JSON ì¶œë ¥ ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
        try:
            env = os.environ.copy()
            env['PROJECT_ROOT'] = str(temp_project_structure)

            result = subprocess.run(
                [script_path, "--json", "--dry-run"],
                capture_output=True,
                text=True,
                timeout=60,
                cwd=str(temp_project_structure),
                env=env
            )

            assert result.returncode == 0, f"JSON ëª¨ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"

            # JSON ì¶œë ¥ í™•ì¸
            try:
                # stderrì—ì„œ JSON ì¶œë ¥ ë¶€ë¶„ ì°¾ê¸°
                output_lines = result.stdout.split('\n')
                json_content = None

                for i, line in enumerate(output_lines):
                    if line.strip().startswith('{'):
                        # JSON ì‹œì‘ì  ì°¾ìŒ, ë‹¤ìŒ ë¼ì¸ë“¤ë„ í¬í•¨í•˜ì—¬ íŒŒì‹± ì‹œë„
                        json_text = '\n'.join(output_lines[i:])
                        json_end = json_text.find('\n}\n')
                        if json_end != -1:
                            json_text = json_text[:json_end + 2]

                        try:
                            json_content = json.loads(json_text)
                            break
                        except json.JSONDecodeError:
                            continue

                if json_content is None:
                    # stdoutì—ì„œ JSONì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ë¡œê·¸ì—ì„œ JSON í˜•ì‹ í™•ì¸
                    assert any("JSON" in line for line in output_lines), "JSON ì¶œë ¥ ê´€ë ¨ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤"
                else:
                    # JSON êµ¬ì¡° ê²€ì¦
                    assert "report_metadata" in json_content
                    assert "performance_summary" in json_content
                    assert "quarterly_comparison" in json_content

            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨í•´ë„ JSON ëª¨ë“œ ì‹¤í–‰ì€ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ í†µê³¼
                pass

        except subprocess.TimeoutExpired:
            pytest.fail("JSON ëª¨ë“œ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ)")
        except Exception as e:
            pytest.fail(f"JSON ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    def test_script_performance_1year_data(self, script_path, temp_project_structure):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: 1ë…„ ë°ì´í„° 60ì´ˆ ì´ë‚´ ì²˜ë¦¬"""
        try:
            # ëŒ€ëŸ‰ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (1ë…„ì¹˜ ì‹œë®¬ë ˆì´ì…˜)
            self._create_large_test_dataset(temp_project_structure)

            env = os.environ.copy()
            env['PROJECT_ROOT'] = str(temp_project_structure)

            start_time = time.time()

            result = subprocess.run(
                [script_path, "--dry-run"],
                capture_output=True,
                text=True,
                timeout=60,  # 60ì´ˆ ì œí•œ
                cwd=str(temp_project_structure),
                env=env
            )

            execution_time = time.time() - start_time

            assert result.returncode == 0, f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"
            assert execution_time < 60, f"ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼: {execution_time:.2f}ì´ˆ (ì œí•œ: 60ì´ˆ)"

            print(f"âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼: {execution_time:.2f}ì´ˆ")

        except subprocess.TimeoutExpired:
            pytest.fail("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: 60ì´ˆ ë‚´ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            pytest.fail(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    def _create_large_test_dataset(self, temp_path: Path):
        """ëŒ€ëŸ‰ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        # 12ê°œì›”ì¹˜ ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
        for month in range(1, 13):
            month_str = f"2024-{month:02d}"
            monthly_report = temp_path / "reports" / "monthly" / f"monthly-report-{month_str}.json"
            with open(monthly_report, 'w', encoding='utf-8') as f:
                json.dump({
                    "report_metadata": {"period_end": f"{month_str}-21"},
                    "backup_operations": {
                        "successful_backups": 25 + (month % 5),
                        "failed_backups": 5 - (month % 5),
                        "cleanup_operations": 8
                    }
                }, f)

        # 365ì¼ì¹˜ CI ë¦¬í¬íŠ¸ ìƒì„± (ë§¤ì¼ 1-3ê°œ)
        base_date = datetime(2024, 1, 1)
        for day in range(365):
            current_date = base_date + timedelta(days=day)
            builds_per_day = 1 + (day % 3)  # 1-3ê°œ ë¹Œë“œ

            for build in range(builds_per_day):
                build_id = day * 10 + build
                ci_report = temp_path / "reports" / "ci_reports" / f"{current_date.strftime('%Y-%m-%d')}-build-{build_id}.json"
                with open(ci_report, 'w', encoding='utf-8') as f:
                    json.dump({
                        "status": "success" if build_id % 5 != 0 else "failed",
                        "execution_time": 180 + (build_id % 100),
                        "coverage": {"percentage": 75 + (build_id % 20)},
                        "timestamp": current_date.isoformat() + "Z"
                    }, f)

        # ëŒ€ëŸ‰ì˜ ë³´ì•ˆ ë¡œê·¸ ìƒì„±
        security_log = temp_path / "logs" / "security.log"
        with open(security_log, 'w', encoding='utf-8') as f:
            for day in range(365):
                current_date = base_date + timedelta(days=day)
                events_per_day = 5 + (day % 10)  # 5-15ê°œ ì´ë²¤íŠ¸

                for event in range(events_per_day):
                    f.write(f"{current_date.strftime('%Y-%m-%d')} {10 + event:02d}:30:00 [INFO] IP_BLOCKED: 192.168.{day % 255}.{event % 255}\n")


class TestYearlyOpsReportCalculations:
    """ì—°ê°„ ì ìˆ˜ ê³„ì‚° ë° ë“±ê¸‰ íŒì • í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.fixture
    def sample_yearly_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ì—°ê°„ ë°ì´í„°"""
        return {
            "report_metadata": {
                "year": 2024,
                "period_start": "2024-01-01",
                "period_end": "2024-12-31",
                "generated_at": "2024-12-31T23:59:59Z",
                "report_type": "yearly_operations"
            },
            "performance_summary": {
                "total_score": 87,
                "grade": "ìš°ìˆ˜",
                "security_score": 28,
                "backup_score": 27,
                "system_score": 16,
                "ci_score": 16
            },
            "quarterly_comparison": {
                "q1_average": 82.5,
                "q2_average": 85.0,
                "q3_average": 88.5,
                "q4_average": 89.0
            },
            "security_events": {
                "blocked_ips": 450,
                "rate_limit_violations": 125,
                "whitelist_additions": 25,
                "total_events": 600,
                "critical_events": [
                    {
                        "date": "2024-03-15",
                        "type": "ë¸Œë£¨íŠ¸í¬ìŠ¤ ê³µê²© ê°ì§€",
                        "detail": "IP: 203.113.*.* (50íšŒ ì‹œë„)"
                    }
                ]
            },
            "backup_operations": {
                "successful_backups": 340,
                "failed_backups": 25,
                "cleanup_operations": 96,
                "success_rate_percent": 93.2
            },
            "system_performance": {
                "average_cpu_usage_percent": 23.5,
                "average_memory_usage_percent": 67.2,
                "average_disk_usage_percent": 45.8,
                "uptime_days": 358,
                "performance_incidents": 12,
                "health_score": 78.5
            },
            "ci_performance": {
                "total_builds": 485,
                "successful_builds": 412,
                "failed_builds": 73,
                "average_build_time_seconds": 245.8,
                "average_test_coverage_percent": 84.3,
                "success_rate_percent": 84.9
            }
        }

    def test_grade_calculation_excellent(self, sample_yearly_data):
        """ìš°ìˆ˜ ë“±ê¸‰ íŒì • í…ŒìŠ¤íŠ¸"""
        data = sample_yearly_data.copy()
        data["performance_summary"]["total_score"] = 95
        data["performance_summary"]["grade"] = "ìš°ìˆ˜"

        assert data["performance_summary"]["total_score"] >= 85
        assert data["performance_summary"]["grade"] == "ìš°ìˆ˜"

    def test_grade_calculation_good(self, sample_yearly_data):
        """ë³´í†µ ë“±ê¸‰ íŒì • í…ŒìŠ¤íŠ¸"""
        data = sample_yearly_data.copy()
        data["performance_summary"]["total_score"] = 75
        data["performance_summary"]["grade"] = "ë³´í†µ"

        assert 70 <= data["performance_summary"]["total_score"] < 85
        assert data["performance_summary"]["grade"] == "ë³´í†µ"

    def test_grade_calculation_needs_improvement(self, sample_yearly_data):
        """ê°œì„  í•„ìš” ë“±ê¸‰ íŒì • í…ŒìŠ¤íŠ¸"""
        data = sample_yearly_data.copy()
        data["performance_summary"]["total_score"] = 65
        data["performance_summary"]["grade"] = "ê°œì„  í•„ìš”"

        assert data["performance_summary"]["total_score"] < 70
        assert data["performance_summary"]["grade"] == "ê°œì„  í•„ìš”"

    def test_score_components_sum(self, sample_yearly_data):
        """ì ìˆ˜ êµ¬ì„± ìš”ì†Œ í•©ê³„ ê²€ì¦"""
        performance = sample_yearly_data["performance_summary"]

        total = (performance["security_score"] +
                performance["backup_score"] +
                performance["system_score"] +
                performance["ci_score"])

        assert total == performance["total_score"], f"ì ìˆ˜ í•©ê³„ ë¶ˆì¼ì¹˜: {total} != {performance['total_score']}"

    def test_quarterly_trend_analysis(self, sample_yearly_data):
        """ë¶„ê¸°ë³„ ì¶”ì´ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        quarterly = sample_yearly_data["quarterly_comparison"]

        # ë¶„ê¸°ë³„ ì ìˆ˜ê°€ ìœ íš¨í•œ ë²”ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
        for quarter, score in quarterly.items():
            assert 0 <= score <= 100, f"{quarter} ì ìˆ˜ê°€ ìœ íš¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨: {score}"

        # ì—°ê°„ ì¶”ì´ ê³„ì‚°
        q1_avg = quarterly["q1_average"]
        q4_avg = quarterly["q4_average"]
        yearly_improvement = q4_avg - q1_avg

        assert isinstance(yearly_improvement, (int, float)), "ì—°ê°„ ê°œì„ ë„ ê³„ì‚° ì˜¤ë¥˜"


class TestYearlyOpsReportNotifications:
    """ì—°ê°„ ë¦¬í¬íŠ¸ ì•Œë¦¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.fixture
    def sample_yearly_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ì—°ê°„ ë°ì´í„° (ì•Œë¦¼ í…ŒìŠ¤íŠ¸ìš©)"""
        return {
            "report_metadata": {
                "year": 2024,
                "generated_at": "2024-12-31T23:59:59Z"
            },
            "performance_summary": {
                "total_score": 87,
                "grade": "ìš°ìˆ˜",
                "security_score": 28,
                "backup_score": 27,
                "system_score": 16,
                "ci_score": 16
            },
            "quarterly_comparison": {
                "q1_average": 82.5,
                "q2_average": 85.0,
                "q3_average": 88.5,
                "q4_average": 89.0
            },
            "security_events": {"total_events": 600, "blocked_ips": 450},
            "backup_operations": {"success_rate_percent": 93.2, "successful_backups": 340},
            "system_performance": {"uptime_days": 358, "performance_incidents": 12},
            "ci_performance": {"success_rate_percent": 84.9, "total_builds": 485}
        }

    @pytest.mark.asyncio
    async def test_notification_level_auto_detection_excellent(self, sample_yearly_data):
        """ìš°ìˆ˜ ë“±ê¸‰ ì•Œë¦¼ ë ˆë²¨ ìë™ íŒì • í…ŒìŠ¤íŠ¸"""
        with patch('mcp.utils.notifier.send_to_slack') as mock_slack, \
             patch('mcp.utils.notifier.send_to_discord') as mock_discord, \
             patch('mcp.utils.notifier.send_to_email') as mock_email, \
             patch('mcp.utils.notifier.log_notification') as mock_log:

            mock_slack.return_value = True
            mock_discord.return_value = True
            mock_email.return_value = True

            # ìš°ìˆ˜ ë“±ê¸‰ (90ì  ì´ìƒ)
            data = sample_yearly_data.copy()
            data["performance_summary"]["total_score"] = 92
            data["performance_summary"]["grade"] = "ìš°ìˆ˜"

            result = await send_yearly_ops_report(data, force_send=True)

            assert result is True
            # INFO ë ˆë²¨ë¡œ ì „ì†¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if mock_slack.called:
                call_args = mock_slack.call_args
                assert call_args[1]["level"] == NotificationLevel.INFO

    @pytest.mark.asyncio
    async def test_notification_level_auto_detection_needs_improvement(self, sample_yearly_data):
        """ê°œì„  í•„ìš” ë“±ê¸‰ ì•Œë¦¼ ë ˆë²¨ ìë™ íŒì • í…ŒìŠ¤íŠ¸"""
        with patch('mcp.utils.notifier.send_to_slack') as mock_slack, \
             patch('mcp.utils.notifier.send_to_discord') as mock_discord, \
             patch('mcp.utils.notifier.send_to_email') as mock_email, \
             patch('mcp.utils.notifier.log_notification') as mock_log:

            mock_slack.return_value = True
            mock_discord.return_value = True
            mock_email.return_value = True

            # ê°œì„  í•„ìš” ë“±ê¸‰
            data = sample_yearly_data.copy()
            data["performance_summary"]["total_score"] = 65
            data["performance_summary"]["grade"] = "ê°œì„  í•„ìš”"

            result = await send_yearly_ops_report(data, force_send=True)

            assert result is True
            # ERROR ë ˆë²¨ë¡œ ì „ì†¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if mock_slack.called:
                call_args = mock_slack.call_args
                assert call_args[1]["level"] == NotificationLevel.ERROR

    @pytest.mark.asyncio
    async def test_notification_rate_limiting(self, sample_yearly_data):
        """ì•Œë¦¼ ì†ë„ ì œí•œ í…ŒìŠ¤íŠ¸ (24ì‹œê°„ ì œí•œ)"""
        with patch('mcp.utils.notifier.send_to_slack') as mock_slack, \
             patch('mcp.utils.notifier.send_to_discord') as mock_discord, \
             patch('mcp.utils.notifier.send_to_email') as mock_email, \
             patch('mcp.utils.notifier.log_notification') as mock_log, \
             patch('time.time') as mock_time:

            mock_slack.return_value = True
            mock_discord.return_value = True
            mock_email.return_value = True

            base_time = 1700000000  # ê¸°ì¤€ ì‹œê°„
            mock_time.return_value = base_time

            # ì²« ë²ˆì§¸ ì „ì†¡ (ì„±ê³µí•´ì•¼ í•¨)
            result1 = await send_yearly_ops_report(sample_yearly_data, force_send=False)
            assert result1 is True

            # ê°™ì€ ì‹œê°„ì— ë‘ ë²ˆì§¸ ì „ì†¡ (ì‹¤íŒ¨í•´ì•¼ í•¨ - 24ì‹œê°„ ì œí•œ)
            result2 = await send_yearly_ops_report(sample_yearly_data, force_send=False)
            assert result2 is False

            # 24ì‹œê°„ í›„ ì „ì†¡ (ì„±ê³µí•´ì•¼ í•¨)
            mock_time.return_value = base_time + 86401  # 24ì‹œê°„ + 1ì´ˆ
            result3 = await send_yearly_ops_report(sample_yearly_data, force_send=False)
            assert result3 is True

    @pytest.mark.asyncio
    async def test_notification_force_send_bypass_rate_limit(self, sample_yearly_data):
        """ê°•ì œ ì „ì†¡ìœ¼ë¡œ ì†ë„ ì œí•œ ìš°íšŒ í…ŒìŠ¤íŠ¸"""
        with patch('mcp.utils.notifier.send_to_slack') as mock_slack, \
             patch('mcp.utils.notifier.send_to_discord') as mock_discord, \
             patch('mcp.utils.notifier.send_to_email') as mock_email, \
             patch('mcp.utils.notifier.log_notification') as mock_log, \
             patch('time.time') as mock_time:

            mock_slack.return_value = True
            mock_discord.return_value = True
            mock_email.return_value = True
            mock_time.return_value = 1700000000

            # ì²« ë²ˆì§¸ ì „ì†¡
            result1 = await send_yearly_ops_report(sample_yearly_data, force_send=False)
            assert result1 is True

            # ê°•ì œ ì „ì†¡ (ì†ë„ ì œí•œ ë¬´ì‹œ)
            result2 = await send_yearly_ops_report(sample_yearly_data, force_send=True)
            assert result2 is True

    @pytest.mark.asyncio
    async def test_notification_message_content(self, sample_yearly_data):
        """ì•Œë¦¼ ë©”ì‹œì§€ ë‚´ìš© ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        with patch('mcp.utils.notifier.send_to_slack') as mock_slack, \
             patch('mcp.utils.notifier.send_to_discord') as mock_discord, \
             patch('mcp.utils.notifier.send_to_email') as mock_email, \
             patch('mcp.utils.notifier.log_notification') as mock_log:

            mock_slack.return_value = True
            mock_discord.return_value = True
            mock_email.return_value = True

            result = await send_yearly_ops_report(sample_yearly_data, force_send=True)
            assert result is True

            # Slack í˜¸ì¶œ í™•ì¸
            if mock_slack.called:
                call_args = mock_slack.call_args
                message = call_args[1]["message"]
                title = call_args[1]["title"]

                # ë©”ì‹œì§€ ë‚´ìš© ê²€ì¦
                assert "2024ë…„ ì—°ê°„ ìš´ì˜ ì„±ê³¼ ìš”ì•½" in message
                assert "87/100ì " in message
                assert "ìš°ìˆ˜" in message
                assert "ğŸ›¡ï¸ ë³´ì•ˆ" in message
                assert "ğŸ“¦ ë°±ì—…" in message
                assert "âš™ï¸ ì‹œìŠ¤í…œ" in message
                assert "ğŸš€ CI/CD" in message

                # ì œëª© ê²€ì¦
                assert "2024ë…„ ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸" in title

    @pytest.mark.asyncio
    async def test_notification_convenience_function(self, sample_yearly_data):
        """í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        with patch('mcp.utils.notifier.send_yearly_ops_report') as mock_send:
            mock_send.return_value = True

            result = await notify_yearly_report(sample_yearly_data, force_send=True)

            assert result is True
            mock_send.assert_called_once_with(sample_yearly_data, force_send=True)

    @pytest.mark.asyncio
    async def test_notification_empty_data_handling(self):
        """ë¹ˆ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        result = await send_yearly_ops_report({}, force_send=True)
        assert result is False

        result = await send_yearly_ops_report(None, force_send=True)
        assert result is False


class TestYearlyOpsReportIntegration:
    """ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    @pytest.mark.integration
    def test_script_execution_with_real_data(self):
        """ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í†µí•© í…ŒìŠ¤íŠ¸"""
        script_path = Path(__file__).parent.parent / "scripts" / "yearly_ops_report.sh"

        if not script_path.exists():
            pytest.skip("yearly_ops_report.sh ìŠ¤í¬ë¦½íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        try:
            result = subprocess.run(
                [str(script_path), "--dry-run", "--verbose"],
                capture_output=True,
                text=True,
                timeout=120  # 2ë¶„ ì œí•œ
            )

            # ìŠ¤í¬ë¦½íŠ¸ê°€ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
            assert result.returncode == 0, f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}"

            # ê¸°ë³¸ì ì¸ ì¶œë ¥ ê²€ì¦
            stderr_output = result.stderr.lower()
            assert any(keyword in stderr_output for keyword in ["ì—°ê°„", "ë¦¬í¬íŠ¸", "ì™„ë£Œ", "ì„±ê³¼"]), \
                "ì˜ˆìƒë˜ëŠ” ì¶œë ¥ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤"

        except subprocess.TimeoutExpired:
            pytest.fail("í†µí•© í…ŒìŠ¤íŠ¸ ì‹œê°„ ì´ˆê³¼ (2ë¶„)")
        except Exception as e:
            pytest.fail(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_end_to_end_notification_flow(self):
        """End-to-End ì•Œë¦¼ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # ì‹¤ì œì™€ ìœ ì‚¬í•œ ì—°ê°„ ë°ì´í„° ìƒì„±
        yearly_data = {
            "report_metadata": {
                "year": 2024,
                "generated_at": datetime.now().isoformat()
            },
            "performance_summary": {
                "total_score": 88,
                "grade": "ìš°ìˆ˜",
                "security_score": 29,
                "backup_score": 28,
                "system_score": 16,
                "ci_score": 15
            },
            "quarterly_comparison": {
                "q1_average": 84.0,
                "q2_average": 86.5,
                "q3_average": 89.0,
                "q4_average": 91.5
            },
            "security_events": {
                "total_events": 750,
                "blocked_ips": 520,
                "rate_limit_violations": 180,
                "whitelist_additions": 50
            },
            "backup_operations": {
                "successful_backups": 355,
                "failed_backups": 10,
                "success_rate_percent": 97.3,
                "cleanup_operations": 104
            },
            "system_performance": {
                "uptime_days": 362,
                "performance_incidents": 8,
                "average_cpu_usage_percent": 21.5,
                "average_memory_usage_percent": 64.8
            },
            "ci_performance": {
                "total_builds": 520,
                "successful_builds": 456,
                "success_rate_percent": 87.7,
                "average_test_coverage_percent": 86.2
            }
        }

        # ì•Œë¦¼ ì‹œìŠ¤í…œ ëª¨í‚¹
        with patch('mcp.utils.notifier.send_to_slack') as mock_slack, \
             patch('mcp.utils.notifier.send_to_discord') as mock_discord, \
             patch('mcp.utils.notifier.send_to_email') as mock_email:

            # ì¼ë¶€ ì±„ë„ ì„±ê³µ, ì¼ë¶€ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
            mock_slack.return_value = True
            mock_discord.return_value = False  # Discord ì‹¤íŒ¨
            mock_email.return_value = True

            result = await send_yearly_ops_report(yearly_data, force_send=True)

            # ì¼ë¶€ ì±„ë„ì´ë¼ë„ ì„±ê³µí•˜ë©´ ì „ì²´ ì„±ê³µìœ¼ë¡œ íŒì •
            assert result is True

            # ê° ì±„ë„ í˜¸ì¶œ ê²€ì¦
            assert mock_slack.called
            assert mock_discord.called
            assert mock_email.called


if __name__ == "__main__":
    # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜
    import asyncio

    async def run_basic_tests():
        """ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        try:
            # ê°„ë‹¨í•œ ì•Œë¦¼ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
            sample_data = {
                "report_metadata": {"year": 2024},
                "performance_summary": {
                    "total_score": 85,
                    "grade": "ìš°ìˆ˜",
                    "security_score": 25,
                    "backup_score": 25,
                    "system_score": 17,
                    "ci_score": 18
                },
                "quarterly_comparison": {"q1_average": 80, "q2_average": 85, "q3_average": 87, "q4_average": 88},
                "security_events": {"total_events": 500},
                "backup_operations": {"success_rate_percent": 95},
                "system_performance": {"uptime_days": 360},
                "ci_performance": {"success_rate_percent": 90}
            }

            with patch('mcp.utils.notifier.send_to_slack') as mock_slack:
                mock_slack.return_value = True
                result = await notify_yearly_report(sample_data, force_send=True)
                print(f"âœ… ì•Œë¦¼ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if result else 'ì‹¤íŒ¨'}")

        except Exception as e:
            print(f"âŒ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        print("ğŸ§ª ì—°ê°„ ìš´ì˜ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(run_basic_tests())