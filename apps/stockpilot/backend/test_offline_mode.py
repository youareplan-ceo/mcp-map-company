#!/usr/bin/env python3
"""
ì˜¤í”„ë¼ì¸ í”„ë¦¬ë·° ëª¨ë“œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import aiohttp
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Any

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OfflineModeTest:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.test_results = []
        self.start_time = None
        
    async def test_endpoint(self, session: aiohttp.ClientSession, endpoint: str, description: str) -> Dict[str, Any]:
        """ê°œë³„ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        try:
            async with session.get(url) as response:
                response_time = (time.time() - start_time) * 1000
                data = await response.json()
                
                # ì˜¤í”„ë¼ì¸ ëª¨ë“œ í‘œì‹œì í™•ì¸
                has_watermark = "watermark" in data or "OFFLINE" in str(data)
                offline_mock_logs = "OFFLINE-MOCK" in str(data)
                
                result = {
                    "endpoint": endpoint,
                    "description": description,
                    "status_code": response.status,
                    "response_time_ms": round(response_time, 2),
                    "success": response.status == 200,
                    "has_watermark": has_watermark,
                    "has_mock_data": bool(data.get("stocks") or data.get("signals") or data.get("portfolio") or data.get("news")),
                    "data_count": len(data.get("stocks", data.get("signals", data.get("portfolio", data.get("news_articles", data.get("results", [])))))),
                    "timestamp": datetime.now().isoformat()
                }
                
                logger.info(f"âœ… {endpoint}: {response.status} ({response_time:.1f}ms) - Watermark: {has_watermark}")
                return result
                
        except Exception as e:
            result = {
                "endpoint": endpoint,
                "description": description,
                "status_code": None,
                "response_time_ms": None,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            logger.error(f"âŒ {endpoint}: {str(e)}")
            return result

    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """í¬ê´„ì ì¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.start_time = time.time()
        logger.info("ğŸ”´ ì˜¤í”„ë¼ì¸ í”„ë¦¬ë·° ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ì—”ë“œí¬ì¸íŠ¸ë“¤
        test_endpoints = [
            ("/", "ë©”ì¸ ì„œë¹„ìŠ¤ ì •ë³´"),
            ("/health", "í—¬ìŠ¤ ì²´í¬"),
            ("/api/v1/stocks/realtime", "ì‹¤ì‹œê°„ ì£¼ì‹ ë°ì´í„°"),
            ("/api/v1/ai/signals", "AI ì‹œê·¸ë„"),
            ("/api/v1/portfolio", "í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°"),
            ("/api/v1/news", "ë‰´ìŠ¤ ë° ê°ì„± ë¶„ì„"),
            ("/api/v1/dashboard/widgets", "ëŒ€ì‹œë³´ë“œ ìœ„ì ¯"),
            ("/api/v1/stocks/search?q=ì‚¼ì„±", "ì£¼ì‹ ê²€ìƒ‰"),
            ("/api/v1/dashboard/summary", "ëŒ€ì‹œë³´ë“œ ìš”ì•½"),
            ("/api/v1/market/status", "ì‹œì¥ ìƒíƒœ")
        ]
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for endpoint, description in test_endpoints:
                task = self.test_endpoint(session, endpoint, description)
                tasks.append(task)
            
            # ëª¨ë“  í…ŒìŠ¤íŠ¸ ë³‘ë ¬ ì‹¤í–‰
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì˜ˆì™¸ ì²˜ë¦¬
            self.test_results = []
            for result in results:
                if isinstance(result, Exception):
                    logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {result}")
                    continue
                self.test_results.append(result)
        
        # ê²°ê³¼ ë¶„ì„
        total_time = time.time() - self.start_time
        analysis = self.analyze_results(total_time)
        
        return analysis

    def analyze_results(self, total_time: float) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        if not self.test_results:
            return {"error": "í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ"}
        
        successful_tests = [r for r in self.test_results if r.get("success", False)]
        failed_tests = [r for r in self.test_results if not r.get("success", True)]
        
        watermarked_tests = [r for r in successful_tests if r.get("has_watermark", False)]
        mock_data_tests = [r for r in successful_tests if r.get("has_mock_data", False)]
        
        response_times = [r["response_time_ms"] for r in successful_tests if r.get("response_time_ms")]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        analysis = {
            "test_summary": {
                "total_tests": len(self.test_results),
                "successful_tests": len(successful_tests),
                "failed_tests": len(failed_tests),
                "success_rate": (len(successful_tests) / len(self.test_results)) * 100,
                "total_execution_time_seconds": round(total_time, 2)
            },
            "offline_mode_verification": {
                "watermarked_responses": len(watermarked_tests),
                "mock_data_responses": len(mock_data_tests),
                "offline_mode_coverage": (len(watermarked_tests) / len(successful_tests)) * 100 if successful_tests else 0
            },
            "performance_metrics": {
                "average_response_time_ms": round(avg_response_time, 2),
                "fastest_response_ms": min(response_times) if response_times else 0,
                "slowest_response_ms": max(response_times) if response_times else 0
            },
            "detailed_results": self.test_results,
            "failed_tests": failed_tests,
            "timestamp": datetime.now().isoformat(),
            "test_passed": len(failed_tests) == 0 and len(watermarked_tests) >= 5  # ìµœì†Œ 5ê°œ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì›Œí„°ë§ˆí¬ í™•ì¸
        }
        
        return analysis

    def print_summary(self, analysis: Dict[str, Any]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ”´ ì˜¤í”„ë¼ì¸ í”„ë¦¬ë·° ëª¨ë“œ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*60)
        
        summary = analysis["test_summary"]
        offline = analysis["offline_mode_verification"]
        performance = analysis["performance_metrics"]
        
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½:")
        print(f"   â€¢ ì´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}")
        print(f"   â€¢ ì„±ê³µ: {summary['successful_tests']}")
        print(f"   â€¢ ì‹¤íŒ¨: {summary['failed_tests']}")
        print(f"   â€¢ ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
        print(f"   â€¢ ì‹¤í–‰ì‹œê°„: {summary['total_execution_time_seconds']}ì´ˆ")
        
        print(f"\nğŸ”´ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ê²€ì¦:")
        print(f"   â€¢ ì›Œí„°ë§ˆí¬ ì‘ë‹µ: {offline['watermarked_responses']}")
        print(f"   â€¢ ëª¨ì˜ ë°ì´í„° ì‘ë‹µ: {offline['mock_data_responses']}")
        print(f"   â€¢ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì»¤ë²„ë¦¬ì§€: {offline['offline_mode_coverage']:.1f}%")
        
        print(f"\nâš¡ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   â€¢ í‰ê·  ì‘ë‹µì‹œê°„: {performance['average_response_time_ms']}ms")
        print(f"   â€¢ ìµœê³  ì†ë„: {performance['fastest_response_ms']}ms")
        print(f"   â€¢ ìµœì € ì†ë„: {performance['slowest_response_ms']}ms")
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ìƒì„¸
        if analysis["failed_tests"]:
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
            for test in analysis["failed_tests"]:
                print(f"   â€¢ {test['endpoint']}: {test.get('error', 'Unknown error')}")
        
        # ìµœì¢… íŒì •
        if analysis["test_passed"]:
            print(f"\nâœ… ì˜¤í”„ë¼ì¸ í”„ë¦¬ë·° ëª¨ë“œ í…ŒìŠ¤íŠ¸ í†µê³¼!")
        else:
            print(f"\nâŒ ì˜¤í”„ë¼ì¸ í”„ë¦¬ë·° ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
        print("="*60)

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = OfflineModeTest()
    analysis = await tester.run_comprehensive_test()
    tester.print_summary(analysis)
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    with open("offline_mode_test_results.json", "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ offline_mode_test_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())