#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
StockPilot ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” í˜ì¼ì˜¤ë²„ ì‹œìŠ¤í…œ
Yahoo Finance, Reuters, Bloomberg ë‹¤ì¤‘í™” ë° ìë™ í˜ì¼ì˜¤ë²„ ë¡œì§
"""

import asyncio
import aiohttp
import json
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import random
from urllib.parse import urlencode
import hashlib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/stockpilot/multi_provider.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataSourceType(Enum):
    """ë°ì´í„° ì†ŒìŠ¤ ìœ í˜•"""
    MARKET_DATA = "market_data"
    NEWS = "news"
    FINANCIAL_REPORTS = "financial_reports"
    ECONOMIC_DATA = "economic_data"

class ProviderStatus(Enum):
    """í”„ë¡œë°”ì´ë” ìƒíƒœ"""
    ACTIVE = "active"
    DEGRADED = "degraded"
    FAILED = "failed"
    MAINTENANCE = "maintenance"

@dataclass
class ProviderConfig:
    """í”„ë¡œë°”ì´ë” ì„¤ì •"""
    name: str
    base_url: str
    api_key: Optional[str]
    timeout: float
    retry_count: int
    priority: int  # ë‚®ì„ìˆ˜ë¡ ìš°ì„ ìˆœìœ„ ë†’ìŒ
    rate_limit: int  # ì´ˆë‹¹ ìš”ì²­ ì œí•œ
    data_types: List[DataSourceType]
    health_check_endpoint: str
    quality_weight: float  # í’ˆì§ˆ ê°€ì¤‘ì¹˜ (0-1)

@dataclass
class ProviderMetrics:
    """í”„ë¡œë°”ì´ë” ë©”íŠ¸ë¦­"""
    provider_name: str
    success_count: int
    failure_count: int
    avg_response_time: float
    last_success: datetime
    last_failure: Optional[datetime]
    current_status: ProviderStatus
    quality_score: float
    uptime_percentage: float

@dataclass
class DataRequest:
    """ë°ì´í„° ìš”ì²­"""
    data_type: DataSourceType
    symbol: str
    parameters: Dict[str, Any]
    max_age_seconds: int = 300  # ìºì‹œ ìµœëŒ€ ìˆ˜ëª…
    require_realtime: bool = False

@dataclass
class DataResponse:
    """ë°ì´í„° ì‘ë‹µ"""
    provider_name: str
    data: Any
    timestamp: datetime
    response_time: float
    quality_score: float
    is_cached: bool = False

class MultiProviderFailover:
    """ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” í˜ì¼ì˜¤ë²„ ë§¤ë‹ˆì €"""
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.providers = self._init_providers()
        self.provider_metrics = {p.name: self._init_metrics(p) for p in self.providers}
        self.cache = {}
        self.rate_limiters = {p.name: {'requests': [], 'window': 1.0} for p in self.providers}
        self.circuit_breakers = {p.name: {'failures': 0, 'last_failure': None, 'state': 'closed'} for p in self.providers}
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
        self.health_check_task = None
        self.metrics_cleanup_task = None
        
    def _init_providers(self) -> List[ProviderConfig]:
        """í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”"""
        return [
            # Yahoo Finance (1ìˆœìœ„ - ë¬´ë£Œ, ì•ˆì •ì )
            ProviderConfig(
                name="yahoo_finance",
                base_url="https://query1.finance.yahoo.com/v8/finance/chart",
                api_key=None,
                timeout=10.0,
                retry_count=3,
                priority=1,
                rate_limit=200,  # ì´ˆë‹¹ 200ìš”ì²­
                data_types=[DataSourceType.MARKET_DATA],
                health_check_endpoint="/",
                quality_weight=0.8
            ),
            
            # Alpha Vantage (2ìˆœìœ„)
            ProviderConfig(
                name="alpha_vantage",
                base_url="https://www.alphavantage.co/query",
                api_key="demo",  # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ API í‚¤ ì‚¬ìš©
                timeout=15.0,
                retry_count=2,
                priority=2,
                rate_limit=5,  # ì´ˆë‹¹ 5ìš”ì²­
                data_types=[DataSourceType.MARKET_DATA, DataSourceType.FINANCIAL_REPORTS],
                health_check_endpoint="",
                quality_weight=0.9
            ),
            
            # Reuters (ë‰´ìŠ¤ ë°ì´í„°)
            ProviderConfig(
                name="reuters_news",
                base_url="https://reuters.com/pf/api/v3/content/fetch",
                api_key=None,
                timeout=12.0,
                retry_count=2,
                priority=1,
                rate_limit=50,
                data_types=[DataSourceType.NEWS],
                health_check_endpoint="/",
                quality_weight=0.95
            ),
            
            # NewsAPI (ë‰´ìŠ¤ ë°±ì—…)
            ProviderConfig(
                name="newsapi",
                base_url="https://newsapi.org/v2",
                api_key="demo",
                timeout=10.0,
                retry_count=3,
                priority=2,
                rate_limit=100,
                data_types=[DataSourceType.NEWS],
                health_check_endpoint="/",
                quality_weight=0.7
            ),
            
            # FRED (ê²½ì œ ë°ì´í„°)
            ProviderConfig(
                name="fred_economic",
                base_url="https://api.stlouisfed.org/fred",
                api_key="demo",
                timeout=8.0,
                retry_count=2,
                priority=1,
                rate_limit=120,
                data_types=[DataSourceType.ECONOMIC_DATA],
                health_check_endpoint="/",
                quality_weight=0.85
            ),
            
            # í•œêµ­ ë°ì´í„° ì†ŒìŠ¤ë“¤
            ProviderConfig(
                name="krx_data",
                base_url="http://data.krx.co.kr/comm",
                api_key=None,
                timeout=15.0,
                retry_count=2,
                priority=1,
                rate_limit=30,
                data_types=[DataSourceType.MARKET_DATA],
                health_check_endpoint="/",
                quality_weight=0.75
            ),
            
            ProviderConfig(
                name="dart_api",
                base_url="https://opendart.fss.or.kr/api",
                api_key="demo",
                timeout=20.0,
                retry_count=2,
                priority=1,
                rate_limit=10,
                data_types=[DataSourceType.FINANCIAL_REPORTS],
                health_check_endpoint="/",
                quality_weight=0.9
            )
        ]
    
    def _init_metrics(self, provider: ProviderConfig) -> ProviderMetrics:
        """í”„ë¡œë°”ì´ë” ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        return ProviderMetrics(
            provider_name=provider.name,
            success_count=0,
            failure_count=0,
            avg_response_time=0.0,
            last_success=datetime.now(timezone.utc),
            last_failure=None,
            current_status=ProviderStatus.ACTIVE,
            quality_score=provider.quality_weight,
            uptime_percentage=100.0
        )
    
    async def get_data(self, request: DataRequest) -> Optional[DataResponse]:
        """ë°ì´í„° ì¡°íšŒ (í˜ì¼ì˜¤ë²„ ë¡œì§ í¬í•¨)"""
        logger.info(f"ë°ì´í„° ìš”ì²­: {request.data_type.value} - {request.symbol}")
        
        # ìºì‹œ í™•ì¸
        if not request.require_realtime:
            cached_response = self._get_from_cache(request)
            if cached_response:
                logger.info(f"ìºì‹œì—ì„œ ë°ì´í„° ë°˜í™˜: {request.symbol}")
                return cached_response
        
        # ìš”ì²­ ìœ í˜•ì— ë§ëŠ” í”„ë¡œë°”ì´ë”ë“¤ ì„ íƒ
        eligible_providers = self._get_eligible_providers(request.data_type)
        
        if not eligible_providers:
            logger.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {request.data_type.value}")
            return None
        
        # í”„ë¡œë°”ì´ë” ìš°ì„ ìˆœìœ„ ì •ë ¬
        sorted_providers = self._sort_providers_by_priority(eligible_providers)
        
        # ê° í”„ë¡œë°”ì´ë” ìˆœì°¨ ì‹œë„
        for provider in sorted_providers:
            if not self._can_make_request(provider):
                logger.warning(f"ìš”ì²­ ì œí•œ ë˜ëŠ” íšŒë¡œ ì°¨ë‹¨ê¸°ë¡œ ì¸í•´ {provider.name} ìŠ¤í‚µ")
                continue
            
            try:
                response = await self._fetch_from_provider(provider, request)
                if response:
                    # ì„±ê³µ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    self._update_success_metrics(provider.name, response.response_time)
                    
                    # ìºì‹œ ì €ì¥
                    self._save_to_cache(request, response)
                    
                    logger.info(f"ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {provider.name} - {request.symbol}")
                    return response
                    
            except Exception as e:
                logger.warning(f"{provider.name}ì—ì„œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                self._update_failure_metrics(provider.name, str(e))
                continue
        
        logger.error(f"ëª¨ë“  í”„ë¡œë°”ì´ë”ì—ì„œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {request.symbol}")
        return None
    
    def _get_eligible_providers(self, data_type: DataSourceType) -> List[ProviderConfig]:
        """ë°ì´í„° ìœ í˜•ì— ë§ëŠ” í”„ë¡œë°”ì´ë” ì„ íƒ"""
        eligible = []
        
        for provider in self.providers:
            if data_type in provider.data_types:
                metrics = self.provider_metrics[provider.name]
                
                # ìƒíƒœ í™•ì¸
                if metrics.current_status in [ProviderStatus.ACTIVE, ProviderStatus.DEGRADED]:
                    eligible.append(provider)
        
        return eligible
    
    def _sort_providers_by_priority(self, providers: List[ProviderConfig]) -> List[ProviderConfig]:
        """í”„ë¡œë°”ì´ë” ìš°ì„ ìˆœìœ„ ì •ë ¬"""
        def priority_score(provider: ProviderConfig) -> float:
            metrics = self.provider_metrics[provider.name]
            
            # ê¸°ë³¸ ìš°ì„ ìˆœìœ„
            score = provider.priority
            
            # í’ˆì§ˆ ì ìˆ˜ ë°˜ì˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            score -= metrics.quality_score * 2
            
            # ì‘ë‹µ ì‹œê°„ ë°˜ì˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            score += metrics.avg_response_time / 1000
            
            # ì„±ê³µë¥  ë°˜ì˜
            total_requests = metrics.success_count + metrics.failure_count
            if total_requests > 0:
                success_rate = metrics.success_count / total_requests
                score -= success_rate * 3
            
            # ìµœê·¼ ì‹¤íŒ¨ íŒ¨ë„í‹°
            if metrics.last_failure and metrics.last_failure > datetime.now(timezone.utc) - timedelta(minutes=5):
                score += 5
            
            return score
        
        return sorted(providers, key=priority_score)
    
    def _can_make_request(self, provider: ProviderConfig) -> bool:
        """ìš”ì²­ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (Rate Limiting, Circuit Breaker)"""
        now = time.time()
        
        # Circuit Breaker í™•ì¸
        circuit_breaker = self.circuit_breakers[provider.name]
        if circuit_breaker['state'] == 'open':
            # 5ë¶„ í›„ half-open ìƒíƒœë¡œ ì „í™˜
            if circuit_breaker['last_failure'] and now - circuit_breaker['last_failure'] > 300:
                circuit_breaker['state'] = 'half-open'
                circuit_breaker['failures'] = 0
                logger.info(f"{provider.name} íšŒë¡œ ì°¨ë‹¨ê¸°: half-open ìƒíƒœë¡œ ì „í™˜")
            else:
                return False
        
        # Rate Limiting í™•ì¸
        rate_limiter = self.rate_limiters[provider.name]
        
        # ì‹œê°„ ìœˆë„ìš° ë‚´ ìš”ì²­ ìˆ˜ ì •ë¦¬
        rate_limiter['requests'] = [
            req_time for req_time in rate_limiter['requests']
            if now - req_time < rate_limiter['window']
        ]
        
        # ìš”ì²­ ì œí•œ í™•ì¸
        if len(rate_limiter['requests']) >= provider.rate_limit:
            return False
        
        # ìš”ì²­ ì‹œê°„ ê¸°ë¡
        rate_limiter['requests'].append(now)
        return True
    
    async def _fetch_from_provider(self, provider: ProviderConfig, request: DataRequest) -> Optional[DataResponse]:
        """íŠ¹ì • í”„ë¡œë°”ì´ë”ì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        start_time = time.time()
        
        try:
            if provider.name == "yahoo_finance":
                data = await self._fetch_yahoo_finance(provider, request)
            elif provider.name == "alpha_vantage":
                data = await self._fetch_alpha_vantage(provider, request)
            elif provider.name == "reuters_news":
                data = await self._fetch_reuters_news(provider, request)
            elif provider.name == "newsapi":
                data = await self._fetch_newsapi(provider, request)
            elif provider.name == "fred_economic":
                data = await self._fetch_fred_economic(provider, request)
            elif provider.name == "krx_data":
                data = await self._fetch_krx_data(provider, request)
            elif provider.name == "dart_api":
                data = await self._fetch_dart_api(provider, request)
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œë°”ì´ë”: {provider.name}")
                return None
            
            response_time = (time.time() - start_time) * 1000
            
            if data:
                # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                quality_score = self._calculate_quality_score(data, provider)
                
                return DataResponse(
                    provider_name=provider.name,
                    data=data,
                    timestamp=datetime.now(timezone.utc),
                    response_time=response_time,
                    quality_score=quality_score,
                    is_cached=False
                )
            
            return None
            
        except Exception as e:
            logger.error(f"{provider.name} ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            raise
    
    async def _fetch_yahoo_finance(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """Yahoo Finance ë°ì´í„° ì¡°íšŒ"""
        try:
            url = f"{provider.base_url}/{request.symbol}"
            params = {
                'interval': request.parameters.get('interval', '1d'),
                'range': request.parameters.get('range', '1mo'),
                'events': 'div,split'
            }
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=provider.timeout)) as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if 'chart' in data and 'result' in data['chart'] and data['chart']['result']:
                            result = data['chart']['result'][0]
                            return {
                                'symbol': request.symbol,
                                'timestamp': result.get('timestamp', []),
                                'indicators': result.get('indicators', {}),
                                'meta': result.get('meta', {}),
                                'source': 'yahoo_finance'
                            }
                    
                    logger.warning(f"Yahoo Finance API ì˜¤ë¥˜: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"Yahoo Finance ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _fetch_alpha_vantage(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """Alpha Vantage ë°ì´í„° ì¡°íšŒ"""
        try:
            params = {
                'function': request.parameters.get('function', 'TIME_SERIES_DAILY'),
                'symbol': request.symbol,
                'apikey': provider.api_key
            }
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=provider.timeout)) as session:
                async with session.get(provider.base_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if 'Error Message' not in data and 'Note' not in data:
                            return {
                                'symbol': request.symbol,
                                'data': data,
                                'source': 'alpha_vantage'
                            }
                    
                    logger.warning(f"Alpha Vantage API ì˜¤ë¥˜: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"Alpha Vantage ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _fetch_reuters_news(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """Reuters ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ"""
        try:
            # Reuters APIëŠ” ì‹¤ì œë¡œëŠ” ë³µì¡í•œ ì¸ì¦ì´ í•„ìš”í•˜ë¯€ë¡œ ì‹œë®¬ë ˆì´ì…˜
            await asyncio.sleep(0.5)  # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Reuters APIë¥¼ í˜¸ì¶œ
            mock_news = [
                {
                    'title': f'{request.symbol} Stock Analysis Update',
                    'summary': f'Latest market analysis for {request.symbol}',
                    'published': datetime.now(timezone.utc).isoformat(),
                    'url': f'https://reuters.com/markets/{request.symbol.lower()}',
                    'sentiment': random.choice(['positive', 'neutral', 'negative']),
                    'relevance': random.uniform(0.7, 1.0)
                }
                for _ in range(random.randint(3, 8))
            ]
            
            return {
                'symbol': request.symbol,
                'articles': mock_news,
                'total_count': len(mock_news),
                'source': 'reuters_news'
            }
            
        except Exception as e:
            logger.error(f"Reuters ë‰´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _fetch_newsapi(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """NewsAPI ë°ì´í„° ì¡°íšŒ"""
        try:
            params = {
                'q': f'{request.symbol} stock',
                'apiKey': provider.api_key,
                'language': 'en',
                'sortBy': 'publishedAt',
                'pageSize': request.parameters.get('limit', 20)
            }
            
            url = f"{provider.base_url}/everything"
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=provider.timeout)) as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get('status') == 'ok':
                            return {
                                'symbol': request.symbol,
                                'articles': data.get('articles', []),
                                'total_results': data.get('totalResults', 0),
                                'source': 'newsapi'
                            }
                    
                    logger.warning(f"NewsAPI ì˜¤ë¥˜: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"NewsAPI ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _fetch_fred_economic(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """FRED ê²½ì œ ë°ì´í„° ì¡°íšŒ"""
        try:
            params = {
                'series_id': request.symbol,
                'api_key': provider.api_key,
                'file_type': 'json'
            }
            
            url = f"{provider.base_url}/series/observations"
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=provider.timeout)) as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if 'observations' in data:
                            return {
                                'series_id': request.symbol,
                                'observations': data['observations'],
                                'source': 'fred_economic'
                            }
                    
                    logger.warning(f"FRED API ì˜¤ë¥˜: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"FRED ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _fetch_krx_data(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """KRX ë°ì´í„° ì¡°íšŒ"""
        try:
            # KRX API ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë³µì¡í•œ POST ìš”ì²­ í•„ìš”)
            await asyncio.sleep(0.8)
            
            mock_data = {
                'symbol': request.symbol,
                'price': random.uniform(10000, 100000),
                'change': random.uniform(-5, 5),
                'volume': random.randint(100000, 10000000),
                'market_cap': random.uniform(1000000000, 100000000000),
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'source': 'krx_data'
            }
            
            return mock_data
            
        except Exception as e:
            logger.error(f"KRX ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _fetch_dart_api(self, provider: ProviderConfig, request: DataRequest) -> Optional[Dict]:
        """DART API ë°ì´í„° ì¡°íšŒ"""
        try:
            params = {
                'crtfc_key': provider.api_key,
                'corp_code': request.symbol,
                'bsns_year': request.parameters.get('year', '2024'),
                'reprt_code': request.parameters.get('report_code', '11011')
            }
            
            url = f"{provider.base_url}/fnlttSinglAcntAll.json"
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=provider.timeout)) as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if data.get('status') == '000':
                            return {
                                'corp_code': request.symbol,
                                'financial_data': data.get('list', []),
                                'source': 'dart_api'
                            }
                    
                    logger.warning(f"DART API ì˜¤ë¥˜: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"DART API ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _calculate_quality_score(self, data: Dict, provider: ProviderConfig) -> float:
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = provider.quality_weight
        
        if not data or not isinstance(data, dict):
            return 0.0
        
        # ë°ì´í„° ì™„ì „ì„± í™•ì¸
        required_fields = ['symbol', 'source']
        present_fields = sum(1 for field in required_fields if field in data and data[field])
        completeness = present_fields / len(required_fields)
        
        # ë°ì´í„° í¬ê¸° í™•ì¸
        data_size_score = min(len(str(data)) / 1000, 1.0)  # 1KB ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        final_score = score * (0.6 * completeness + 0.4 * data_size_score)
        
        return min(max(final_score, 0.0), 1.0)
    
    def _get_from_cache(self, request: DataRequest) -> Optional[DataResponse]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        cache_key = self._generate_cache_key(request)
        
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            
            # ìºì‹œ ìœ íš¨ì„± í™•ì¸
            age = (datetime.now(timezone.utc) - cached_item['timestamp']).total_seconds()
            if age <= request.max_age_seconds:
                response = cached_item['response']
                response.is_cached = True
                return response
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self.cache[cache_key]
        
        return None
    
    def _save_to_cache(self, request: DataRequest, response: DataResponse):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        cache_key = self._generate_cache_key(request)
        
        self.cache[cache_key] = {
            'timestamp': datetime.now(timezone.utc),
            'response': response
        }
        
        # ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 1000ê°œ í•­ëª©)
        if len(self.cache) > 1000:
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]
    
    def _generate_cache_key(self, request: DataRequest) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{request.data_type.value}:{request.symbol}:{json.dumps(request.parameters, sort_keys=True)}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _update_success_metrics(self, provider_name: str, response_time: float):
        """ì„±ê³µ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        metrics = self.provider_metrics[provider_name]
        
        metrics.success_count += 1
        metrics.last_success = datetime.now(timezone.utc)
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸ (ì§€ìˆ˜ í‰í™œë²•)
        alpha = 0.3
        metrics.avg_response_time = alpha * response_time + (1 - alpha) * metrics.avg_response_time
        
        # ê°€ìš©ì„± ê³„ì‚°
        total_requests = metrics.success_count + metrics.failure_count
        metrics.uptime_percentage = (metrics.success_count / total_requests) * 100
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        if metrics.uptime_percentage >= 95:
            metrics.current_status = ProviderStatus.ACTIVE
        elif metrics.uptime_percentage >= 80:
            metrics.current_status = ProviderStatus.DEGRADED
        else:
            metrics.current_status = ProviderStatus.FAILED
        
        # Circuit Breaker ì¬ì„¤ì •
        circuit_breaker = self.circuit_breakers[provider_name]
        if circuit_breaker['state'] == 'half-open':
            circuit_breaker['state'] = 'closed'
            circuit_breaker['failures'] = 0
    
    def _update_failure_metrics(self, provider_name: str, error: str):
        """ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        metrics = self.provider_metrics[provider_name]
        
        metrics.failure_count += 1
        metrics.last_failure = datetime.now(timezone.utc)
        
        # ê°€ìš©ì„± ê³„ì‚°
        total_requests = metrics.success_count + metrics.failure_count
        metrics.uptime_percentage = (metrics.success_count / total_requests) * 100
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        if metrics.uptime_percentage < 80:
            metrics.current_status = ProviderStatus.FAILED
        elif metrics.uptime_percentage < 95:
            metrics.current_status = ProviderStatus.DEGRADED
        
        # Circuit Breaker ì—…ë°ì´íŠ¸
        circuit_breaker = self.circuit_breakers[provider_name]
        circuit_breaker['failures'] += 1
        circuit_breaker['last_failure'] = time.time()
        
        # 5íšŒ ì—°ì† ì‹¤íŒ¨ì‹œ íšŒë¡œ ì°¨ë‹¨
        if circuit_breaker['failures'] >= 5:
            circuit_breaker['state'] = 'open'
            logger.warning(f"{provider_name} íšŒë¡œ ì°¨ë‹¨ê¸° í™œì„±í™” (5íšŒ ì—°ì† ì‹¤íŒ¨)")
    
    async def health_check_all_providers(self):
        """ëª¨ë“  í”„ë¡œë°”ì´ë” í—¬ìŠ¤ ì²´í¬"""
        logger.info("ì „ì²´ í”„ë¡œë°”ì´ë” í—¬ìŠ¤ ì²´í¬ ì‹œì‘")
        
        tasks = []
        for provider in self.providers:
            task = asyncio.create_task(self._health_check_provider(provider))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        healthy_count = sum(1 for result in results if result is True)
        logger.info(f"í—¬ìŠ¤ ì²´í¬ ì™„ë£Œ: {healthy_count}/{len(self.providers)} í”„ë¡œë°”ì´ë” ì •ìƒ")
        
        return results
    
    async def _health_check_provider(self, provider: ProviderConfig) -> bool:
        """ê°œë³„ í”„ë¡œë°”ì´ë” í—¬ìŠ¤ ì²´í¬"""
        try:
            start_time = time.time()
            
            # ê°„ë‹¨í•œ í—¬ìŠ¤ ì²´í¬ ìš”ì²­
            test_request = DataRequest(
                data_type=provider.data_types[0],
                symbol="AAPL",  # í…ŒìŠ¤íŠ¸ìš© ì‹¬ë³¼
                parameters={},
                max_age_seconds=0  # ìºì‹œ ì‚¬ìš© ì•ˆ í•¨
            )
            
            response = await self._fetch_from_provider(provider, test_request)
            response_time = (time.time() - start_time) * 1000
            
            if response:
                self._update_success_metrics(provider.name, response_time)
                logger.debug(f"{provider.name} í—¬ìŠ¤ ì²´í¬ ì„±ê³µ ({response_time:.1f}ms)")
                return True
            else:
                self._update_failure_metrics(provider.name, "Health check failed")
                logger.warning(f"{provider.name} í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            self._update_failure_metrics(provider.name, f"Health check error: {str(e)}")
            logger.error(f"{provider.name} í—¬ìŠ¤ ì²´í¬ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def get_provider_status(self) -> Dict[str, Dict]:
        """ëª¨ë“  í”„ë¡œë°”ì´ë” ìƒíƒœ ì¡°íšŒ"""
        status_report = {}
        
        for provider in self.providers:
            metrics = self.provider_metrics[provider.name]
            circuit_breaker = self.circuit_breakers[provider.name]
            
            status_report[provider.name] = {
                'status': metrics.current_status.value,
                'uptime_percentage': round(metrics.uptime_percentage, 2),
                'success_count': metrics.success_count,
                'failure_count': metrics.failure_count,
                'avg_response_time': round(metrics.avg_response_time, 2),
                'quality_score': round(metrics.quality_score, 2),
                'last_success': metrics.last_success.isoformat() if metrics.last_success else None,
                'last_failure': metrics.last_failure.isoformat() if metrics.last_failure else None,
                'circuit_breaker_state': circuit_breaker['state'],
                'data_types': [dt.value for dt in provider.data_types],
                'priority': provider.priority
            }
        
        return status_report
    
    async def start_background_tasks(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘"""
        logger.info("ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘")
        
        # í—¬ìŠ¤ ì²´í¬ ì‘ì—… (5ë¶„ë§ˆë‹¤)
        self.health_check_task = asyncio.create_task(self._periodic_health_check())
        
        # ë©”íŠ¸ë¦­ ì •ë¦¬ ì‘ì—… (1ì‹œê°„ë§ˆë‹¤)
        self.metrics_cleanup_task = asyncio.create_task(self._periodic_metrics_cleanup())
    
    async def _periodic_health_check(self):
        """ì£¼ê¸°ì  í—¬ìŠ¤ ì²´í¬"""
        while True:
            try:
                await asyncio.sleep(300)  # 5ë¶„ ëŒ€ê¸°
                await self.health_check_all_providers()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ì£¼ê¸°ì  í—¬ìŠ¤ ì²´í¬ ì˜¤ë¥˜: {str(e)}")
    
    async def _periodic_metrics_cleanup(self):
        """ì£¼ê¸°ì  ë©”íŠ¸ë¦­ ì •ë¦¬"""
        while True:
            try:
                await asyncio.sleep(3600)  # 1ì‹œê°„ ëŒ€ê¸°
                
                # ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬
                now = datetime.now(timezone.utc)
                expired_keys = []
                
                for key, item in self.cache.items():
                    age = (now - item['timestamp']).total_seconds()
                    if age > 3600:  # 1ì‹œê°„ ì´ìƒ ëœ ìºì‹œ ì‚­ì œ
                        expired_keys.append(key)
                
                for key in expired_keys:
                    del self.cache[key]
                
                if expired_keys:
                    logger.info(f"ë§Œë£Œëœ ìºì‹œ {len(expired_keys)}ê°œ ì •ë¦¬ ì™„ë£Œ")
                
                # Rate Limiter ì •ë¦¬
                current_time = time.time()
                for provider_name, rate_limiter in self.rate_limiters.items():
                    rate_limiter['requests'] = [
                        req_time for req_time in rate_limiter['requests']
                        if current_time - req_time < rate_limiter['window']
                    ]
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ì£¼ê¸°ì  ë©”íŠ¸ë¦­ ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    async def stop_background_tasks(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¤‘ë‹¨"""
        logger.info("ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¤‘ë‹¨")
        
        if self.health_check_task:
            self.health_check_task.cancel()
        
        if self.metrics_cleanup_task:
            self.metrics_cleanup_task.cancel()

async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    try:
        logger.info("ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” í˜ì¼ì˜¤ë²„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        failover = MultiProviderFailover()
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
        await failover.start_background_tasks()
        
        # ë‹¤ì–‘í•œ ë°ì´í„° ìš”ì²­ í…ŒìŠ¤íŠ¸
        test_requests = [
            DataRequest(DataSourceType.MARKET_DATA, "AAPL", {"interval": "1d"}),
            DataRequest(DataSourceType.MARKET_DATA, "005930", {"interval": "1d"}),  # ì‚¼ì„±ì „ì
            DataRequest(DataSourceType.NEWS, "TSLA", {"limit": 10}),
            DataRequest(DataSourceType.ECONOMIC_DATA, "GDP", {}),
            DataRequest(DataSourceType.FINANCIAL_REPORTS, "MSFT", {"year": "2024"})
        ]
        
        print("\n" + "="*60)
        print("ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” í˜ì¼ì˜¤ë²„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        print("="*60)
        
        for i, request in enumerate(test_requests, 1):
            print(f"\n{i}. í…ŒìŠ¤íŠ¸ ìš”ì²­: {request.data_type.value} - {request.symbol}")
            
            response = await failover.get_data(request)
            if response:
                print(f"   âœ“ ì„±ê³µ: {response.provider_name}")
                print(f"   ì‘ë‹µ ì‹œê°„: {response.response_time:.1f}ms")
                print(f"   í’ˆì§ˆ ì ìˆ˜: {response.quality_score:.2f}")
                print(f"   ìºì‹œ ì—¬ë¶€: {'Yes' if response.is_cached else 'No'}")
            else:
                print("   âœ— ì‹¤íŒ¨: ëª¨ë“  í”„ë¡œë°”ì´ë”ì—ì„œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
        
        # í”„ë¡œë°”ì´ë” ìƒíƒœ ì¶œë ¥
        print(f"\n{'='*60}")
        print("í”„ë¡œë°”ì´ë” ìƒíƒœ ìš”ì•½")
        print("="*60)
        
        status_report = failover.get_provider_status()
        for provider_name, status in status_report.items():
            status_emoji = {
                'active': 'ğŸŸ¢',
                'degraded': 'ğŸŸ¡',
                'failed': 'ğŸ”´',
                'maintenance': 'ğŸ”§'
            }.get(status['status'], 'âšª')
            
            print(f"\n{status_emoji} {provider_name}:")
            print(f"   ìƒíƒœ: {status['status']}")
            print(f"   ê°€ë™ìœ¨: {status['uptime_percentage']:.1f}%")
            print(f"   ì„±ê³µ/ì‹¤íŒ¨: {status['success_count']}/{status['failure_count']}")
            print(f"   í‰ê·  ì‘ë‹µì‹œê°„: {status['avg_response_time']:.1f}ms")
            print(f"   í’ˆì§ˆ ì ìˆ˜: {status['quality_score']:.2f}")
            print(f"   íšŒë¡œ ì°¨ë‹¨ê¸°: {status['circuit_breaker_state']}")
        
        # ì ì‹œ ëŒ€ê¸° í›„ í—¬ìŠ¤ ì²´í¬
        print(f"\n{'='*60}")
        print("ì „ì²´ í”„ë¡œë°”ì´ë” í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰...")
        
        health_results = await failover.health_check_all_providers()
        healthy_count = sum(1 for result in health_results if result is True)
        
        print(f"í—¬ìŠ¤ ì²´í¬ ê²°ê³¼: {healthy_count}/{len(health_results)} í”„ë¡œë°”ì´ë” ì •ìƒ")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¤‘ë‹¨
        await failover.stop_background_tasks()
        
        print(f"\n{'='*60}")
        print("ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” í˜ì¼ì˜¤ë²„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("="*60)
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())