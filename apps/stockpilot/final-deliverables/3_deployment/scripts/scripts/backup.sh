#!/bin/bash
# StockPilot ë°±ì—… ë° ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
# ë°ì´í„°ë² ì´ìŠ¤, íŒŒì¼, ì„¤ì • ë“±ì„ ìë™ìœ¼ë¡œ ë°±ì—…í•˜ê³  ë³µêµ¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

set -euo pipefail

# ìŠ¤í¬ë¦½íŠ¸ ì •ë³´
SCRIPT_NAME="StockPilot ë°±ì—…/ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸"
VERSION="1.0.0"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# ê¸°ë³¸ ì„¤ì •
DEFAULT_BACKUP_DIR="/var/backups/stockpilot"
DEFAULT_RETENTION_DAYS=30
DEFAULT_S3_BUCKET=""

# ìƒ‰ìƒ ì½”ë“œ
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ë¡œê¹… í•¨ìˆ˜
log_info() {
    echo -e "${BLUE}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') $1"
}

# ë°°ë„ˆ ì¶œë ¥
print_banner() {
    echo "=================================================="
    echo "    $SCRIPT_NAME v$VERSION"
    echo "=================================================="
    echo ""
}

# ë„ì›€ë§ ì¶œë ¥
show_help() {
    cat << EOF
ì‚¬ìš©ë²•: $0 [ëª…ë ¹] [ì˜µì…˜]

ëª…ë ¹:
    backup          ë°±ì—… ì‹¤í–‰
    restore         ë³µêµ¬ ì‹¤í–‰
    list            ë°±ì—… ëª©ë¡ ì¡°íšŒ
    cleanup         ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
    test            ë°±ì—… í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë°±ì—… ì•ˆí•¨)

ë°±ì—… ì˜µì…˜:
    --type TYPE     ë°±ì—… íƒ€ì… (all|db|files|config) [ê¸°ë³¸ê°’: all]
    --dir DIR       ë°±ì—… ì €ì¥ ë””ë ‰í† ë¦¬ [ê¸°ë³¸ê°’: $DEFAULT_BACKUP_DIR]
    --compress      ì••ì¶• í™œì„±í™”
    --encrypt       ì•”í˜¸í™” í™œì„±í™”
    --s3            S3ì— ì—…ë¡œë“œ
    --name NAME     ë°±ì—… ì´ë¦„ ì§€ì •

ë³µêµ¬ ì˜µì…˜:
    --backup NAME   ë³µêµ¬í•  ë°±ì—… ì´ë¦„
    --type TYPE     ë³µêµ¬ íƒ€ì… (all|db|files|config)
    --force         í™•ì¸ ì—†ì´ ê°•ì œ ë³µêµ¬

ê³µí†µ ì˜µì…˜:
    --config FILE   ì„¤ì • íŒŒì¼ ì§€ì •
    --verbose       ìƒì„¸ ë¡œê·¸ ì¶œë ¥
    --help          ì´ ë„ì›€ë§ í‘œì‹œ

ì˜ˆì‹œ:
    $0 backup --type all --compress --encrypt
    $0 backup --type db --s3
    $0 restore --backup stockpilot_20231201_120000 --type db
    $0 list
    $0 cleanup --days 30

EOF
}

# ì„¤ì • ë¡œë“œ
load_config() {
    local config_file="${CONFIG_FILE:-$PROJECT_ROOT/.env}"
    
    if [[ -f "$config_file" ]]; then
        log_info "ì„¤ì • íŒŒì¼ ë¡œë“œ: $config_file"
        source "$config_file"
    else
        log_warning "ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $config_file"
    fi
    
    # ë°±ì—… ì„¤ì • ë³€ìˆ˜ë“¤
    export BACKUP_DIR="${BACKUP_PATH:-$DEFAULT_BACKUP_DIR}"
    export RETENTION_DAYS="${BACKUP_RETENTION_DAYS:-$DEFAULT_RETENTION_DAYS}"
    export COMPRESS_BACKUPS="${BACKUP_COMPRESS:-true}"
    export ENCRYPT_BACKUPS="${BACKUP_ENCRYPT:-false}"
    export ENCRYPTION_KEY="${DB_BACKUP_ENCRYPT_KEY:-}"
    export S3_ENABLED="${S3_BACKUP_ENABLED:-false}"
    export S3_BUCKET="${S3_BUCKET:-$DEFAULT_S3_BUCKET}"
    export S3_ACCESS_KEY="${S3_ACCESS_KEY:-}"
    export S3_SECRET_KEY="${S3_SECRET_KEY:-}"
    export S3_REGION="${S3_REGION:-ap-northeast-2}"
}

# ë°±ì—… ë””ë ‰í† ë¦¬ ì¤€ë¹„
prepare_backup_dir() {
    local backup_name="$1"
    local backup_path="$BACKUP_DIR/$backup_name"
    
    log_info "ë°±ì—… ë””ë ‰í† ë¦¬ ì¤€ë¹„: $backup_path"
    
    # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
    if [[ ! -d "$BACKUP_DIR" ]]; then
        sudo mkdir -p "$BACKUP_DIR"
        sudo chown $USER:$USER "$BACKUP_DIR" 2>/dev/null || true
    fi
    
    mkdir -p "$backup_path"
    echo "$backup_path"
}

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
backup_database() {
    local backup_path="$1"
    
    if [[ -z "${DATABASE_URL:-}" ]]; then
        log_warning "DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤"
        return
    fi
    
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹œì‘"
    
    local db_backup_file="$backup_path/database.sql"
    
    # PostgreSQL ë°±ì—…
    if [[ "$DATABASE_URL" =~ ^postgresql:// ]]; then
        log_info "PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"
        
        # ìŠ¤í‚¤ë§ˆì™€ ë°ì´í„° ëª¨ë‘ ë°±ì—…
        pg_dump "$DATABASE_URL" \
            --verbose \
            --format=custom \
            --file="$db_backup_file.backup" \
            || {
                log_error "PostgreSQL ë°±ì—… ì‹¤íŒ¨"
                return 1
            }
            
        # í…ìŠ¤íŠ¸ í˜•íƒœë¡œë„ ë°±ì—… (ë³µêµ¬ ì‹œ í¸ì˜ë¥¼ ìœ„í•´)
        pg_dump "$DATABASE_URL" \
            --verbose \
            --format=plain \
            --file="$db_backup_file" \
            || {
                log_warning "í…ìŠ¤íŠ¸ í˜•íƒœ PostgreSQL ë°±ì—… ì‹¤íŒ¨"
            }
            
    else
        log_error "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì…ë‹ˆë‹¤"
        return 1
    fi
    
    # ì••ì¶•
    if [[ "$COMPRESS_BACKUPS" == "true" ]]; then
        log_info "ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì••ì¶• ì¤‘"
        gzip "$db_backup_file"
        gzip "$db_backup_file.backup" 2>/dev/null || true
    fi
    
    log_success "ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ"
}

# ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë°±ì—…
backup_files() {
    local backup_path="$1"
    
    log_info "ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë°±ì—… ì‹œì‘"
    
    local files_backup_file="$backup_path/application_files.tar"
    
    # ë°±ì—…í•  íŒŒì¼ê³¼ ë””ë ‰í† ë¦¬ë“¤
    local backup_items=(
        "backend"
        "frontend"
        "scripts"
        "docs"
        ".env.example"
        ".env.production.example"
        "docker-compose.yml"
        "docker-compose.production.yml"
        "README.md"
    )
    
    # ì œì™¸í•  íŒ¨í„´ë“¤
    local exclude_patterns=(
        "--exclude=node_modules"
        "--exclude=venv"
        "--exclude=.git"
        "--exclude=__pycache__"
        "--exclude=*.pyc"
        "--exclude=.DS_Store"
        "--exclude=*.log"
        "--exclude=build"
        "--exclude=dist"
        "--exclude=.coverage"
        "--exclude=htmlcov"
    )
    
    cd "$PROJECT_ROOT"
    
    # tarë¡œ ë°±ì—… ìƒì„±
    tar "${exclude_patterns[@]}" -cf "$files_backup_file" "${backup_items[@]}" 2>/dev/null || {
        log_error "íŒŒì¼ ë°±ì—… ì‹¤íŒ¨"
        return 1
    }
    
    # ì••ì¶•
    if [[ "$COMPRESS_BACKUPS" == "true" ]]; then
        log_info "íŒŒì¼ ë°±ì—… ì••ì¶• ì¤‘"
        gzip "$files_backup_file"
    fi
    
    log_success "ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë°±ì—… ì™„ë£Œ"
}

# ì„¤ì • íŒŒì¼ ë°±ì—…
backup_config() {
    local backup_path="$1"
    
    log_info "ì„¤ì • íŒŒì¼ ë°±ì—… ì‹œì‘"
    
    local config_backup_dir="$backup_path/config"
    mkdir -p "$config_backup_dir"
    
    # ë°±ì—…í•  ì„¤ì • íŒŒì¼ë“¤
    local config_files=(
        ".env"
        ".env.production"
        ".env.staging"
        "docker-compose.yml"
        "docker-compose.production.yml"
        "docker-compose.staging.yml"
        "nginx.conf"
        "/etc/systemd/system/stockpilot.service"
    )
    
    for config_file in "${config_files[@]}"; do
        local full_path=""
        
        # ì ˆëŒ€ ê²½ë¡œì¸ì§€ í™•ì¸
        if [[ "$config_file" =~ ^/ ]]; then
            full_path="$config_file"
        else
            full_path="$PROJECT_ROOT/$config_file"
        fi
        
        if [[ -f "$full_path" ]]; then
            log_info "ì„¤ì • íŒŒì¼ ë°±ì—…: $config_file"
            cp "$full_path" "$config_backup_dir/"
        else
            log_warning "ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $config_file"
        fi
    done
    
    # ë©”íƒ€ë°ì´í„° ìƒì„±
    cat > "$config_backup_dir/metadata.txt" << EOF
ë°±ì—… ìƒì„± ì‹œê°„: $(date)
í˜¸ìŠ¤íŠ¸ëª…: $(hostname)
ì‚¬ìš©ì: $(whoami)
Git ë¸Œëœì¹˜: $(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "unknown")
Git ì»¤ë°‹: $(git rev-parse --short HEAD 2>/dev/null || echo "unknown")
Python ë²„ì „: $(python3 --version 2>/dev/null || echo "unknown")
Node ë²„ì „: $(node --version 2>/dev/null || echo "unknown")
Docker ë²„ì „: $(docker --version 2>/dev/null || echo "unknown")
EOF
    
    log_success "ì„¤ì • íŒŒì¼ ë°±ì—… ì™„ë£Œ"
}

# ë°±ì—… ì•”í˜¸í™”
encrypt_backup() {
    local backup_path="$1"
    
    if [[ "$ENCRYPT_BACKUPS" != "true" ]] || [[ -z "$ENCRYPTION_KEY" ]]; then
        return
    fi
    
    log_info "ë°±ì—… ì•”í˜¸í™” ì¤‘"
    
    # ë°±ì—… ë””ë ‰í† ë¦¬ë¥¼ tarë¡œ ì••ì¶•
    local encrypted_file="$backup_path.encrypted.tar.gz"
    
    tar -czf - -C "$(dirname "$backup_path")" "$(basename "$backup_path")" | \
    openssl enc -aes-256-cbc -salt -pbkdf2 -pass pass:"$ENCRYPTION_KEY" -out "$encrypted_file"
    
    if [[ $? -eq 0 ]]; then
        # ì›ë³¸ ë””ë ‰í† ë¦¬ ì‚­ì œ
        rm -rf "$backup_path"
        log_success "ë°±ì—… ì•”í˜¸í™” ì™„ë£Œ: $encrypted_file"
        echo "$encrypted_file"
    else
        log_error "ë°±ì—… ì•”í˜¸í™” ì‹¤íŒ¨"
        return 1
    fi
}

# S3 ì—…ë¡œë“œ
upload_to_s3() {
    local backup_file="$1"
    local backup_name="$(basename "$backup_file")"
    
    if [[ "$S3_ENABLED" != "true" ]] || [[ -z "$S3_BUCKET" ]]; then
        return
    fi
    
    log_info "S3ì— ë°±ì—… ì—…ë¡œë“œ ì¤‘: $backup_name"
    
    # AWS CLI ì„¤ì •
    export AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY"
    export AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY"
    export AWS_DEFAULT_REGION="$S3_REGION"
    
    # S3 ì—…ë¡œë“œ
    if command -v aws >/dev/null 2>&1; then
        aws s3 cp "$backup_file" "s3://$S3_BUCKET/stockpilot-backups/$backup_name" || {
            log_error "S3 ì—…ë¡œë“œ ì‹¤íŒ¨"
            return 1
        }
        
        # ë°±ì—… ë©”íƒ€ë°ì´í„°ë„ ì—…ë¡œë“œ
        local metadata_file="/tmp/backup_metadata_$backup_name.json"
        cat > "$metadata_file" << EOF
{
    "backup_name": "$backup_name",
    "created_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "hostname": "$(hostname)",
    "git_commit": "$(git rev-parse --short HEAD 2>/dev/null || echo "unknown")",
    "file_size": $(stat -f%z "$backup_file" 2>/dev/null || stat -c%s "$backup_file" 2>/dev/null || echo "0")
}
EOF
        
        aws s3 cp "$metadata_file" "s3://$S3_BUCKET/stockpilot-backups/metadata/$backup_name.json"
        rm -f "$metadata_file"
        
        log_success "S3 ì—…ë¡œë“œ ì™„ë£Œ"
    else
        log_error "AWS CLIê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"
        return 1
    fi
}

# ë°±ì—… ì‹¤í–‰
run_backup() {
    local backup_type="${BACKUP_TYPE:-all}"
    local backup_name="${BACKUP_NAME:-stockpilot_$(date '+%Y%m%d_%H%M%S')}"
    
    log_info "ë°±ì—… ì‹œì‘ - íƒ€ì…: $backup_type, ì´ë¦„: $backup_name"
    
    local backup_path=$(prepare_backup_dir "$backup_name")
    
    # ë°±ì—… íƒ€ì…ì— ë”°ë¥¸ ì‹¤í–‰
    case $backup_type in
        all)
            backup_database "$backup_path"
            backup_files "$backup_path"
            backup_config "$backup_path"
            ;;
        db)
            backup_database "$backup_path"
            ;;
        files)
            backup_files "$backup_path"
            ;;
        config)
            backup_config "$backup_path"
            ;;
        *)
            log_error "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°±ì—… íƒ€ì…: $backup_type"
            return 1
            ;;
    esac
    
    # ë°±ì—… ì™„ë£Œ ì •ë³´ ì €ì¥
    cat > "$backup_path/backup_info.txt" << EOF
ë°±ì—… ì´ë¦„: $backup_name
ë°±ì—… íƒ€ì…: $backup_type
ìƒì„± ì‹œê°„: $(date)
í˜¸ìŠ¤íŠ¸ëª…: $(hostname)
ë°±ì—… í¬ê¸°: $(du -sh "$backup_path" | cut -f1)
EOF
    
    # ì•”í˜¸í™”
    local final_backup_path="$backup_path"
    if [[ "$ENCRYPT_BACKUPS" == "true" ]]; then
        final_backup_path=$(encrypt_backup "$backup_path")
    fi
    
    # S3 ì—…ë¡œë“œ
    if [[ "$S3_ENABLED" == "true" ]]; then
        if [[ -f "$final_backup_path" ]]; then
            upload_to_s3 "$final_backup_path"
        else
            # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ì••ì¶• í›„ ì—…ë¡œë“œ
            local temp_archive="/tmp/${backup_name}.tar.gz"
            tar -czf "$temp_archive" -C "$(dirname "$final_backup_path")" "$(basename "$final_backup_path")"
            upload_to_s3 "$temp_archive"
            rm -f "$temp_archive"
        fi
    fi
    
    log_success "ë°±ì—… ì™„ë£Œ: $backup_name"
    log_info "ë°±ì—… ìœ„ì¹˜: $final_backup_path"
}

# ë°±ì—… ëª©ë¡ ì¡°íšŒ
list_backups() {
    log_info "ë°±ì—… ëª©ë¡ ì¡°íšŒ"
    
    if [[ ! -d "$BACKUP_DIR" ]]; then
        log_warning "ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: $BACKUP_DIR"
        return
    fi
    
    echo ""
    echo "ë¡œì»¬ ë°±ì—… ëª©ë¡:"
    echo "----------------------------------------"
    
    local found_backups=false
    for backup in "$BACKUP_DIR"/stockpilot_*; do
        if [[ -e "$backup" ]]; then
            local backup_name=$(basename "$backup")
            local backup_date="unknown"
            local backup_size="unknown"
            
            # ë°±ì—… ì •ë³´ íŒŒì¼ì—ì„œ ì •ë³´ ì¶”ì¶œ
            if [[ -f "$backup/backup_info.txt" ]]; then
                backup_date=$(grep "ìƒì„± ì‹œê°„:" "$backup/backup_info.txt" | cut -d: -f2- | xargs)
                backup_size=$(grep "ë°±ì—… í¬ê¸°:" "$backup/backup_info.txt" | cut -d: -f2 | xargs)
            elif [[ -f "$backup" ]]; then
                backup_date=$(stat -f%Sm -t "%Y-%m-%d %H:%M:%S" "$backup" 2>/dev/null || stat -c %y "$backup" 2>/dev/null | cut -d. -f1)
                backup_size=$(du -sh "$backup" | cut -f1)
            elif [[ -d "$backup" ]]; then
                backup_date=$(stat -f%Sm -t "%Y-%m-%d %H:%M:%S" "$backup" 2>/dev/null || stat -c %y "$backup" 2>/dev/null | cut -d. -f1)
                backup_size=$(du -sh "$backup" | cut -f1)
            fi
            
            echo "ì´ë¦„: $backup_name"
            echo "ìƒì„±: $backup_date"
            echo "í¬ê¸°: $backup_size"
            echo "ê²½ë¡œ: $backup"
            echo ""
            found_backups=true
        fi
    done
    
    if [[ "$found_backups" != "true" ]]; then
        echo "ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    fi
    
    # S3 ë°±ì—… ëª©ë¡ë„ ì¡°íšŒ
    if [[ "$S3_ENABLED" == "true" ]] && command -v aws >/dev/null 2>&1; then
        echo ""
        echo "S3 ë°±ì—… ëª©ë¡:"
        echo "----------------------------------------"
        
        export AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY"
        export AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY"
        export AWS_DEFAULT_REGION="$S3_REGION"
        
        aws s3 ls "s3://$S3_BUCKET/stockpilot-backups/" --human-readable || {
            log_warning "S3 ë°±ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨"
        }
    fi
}

# ë°±ì—… ë³µêµ¬
restore_backup() {
    local backup_name="$1"
    local restore_type="${RESTORE_TYPE:-all}"
    
    if [[ -z "$backup_name" ]]; then
        log_error "ë³µêµ¬í•  ë°±ì—… ì´ë¦„ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤"
        return 1
    fi
    
    log_info "ë°±ì—… ë³µêµ¬ ì‹œì‘ - ë°±ì—…: $backup_name, íƒ€ì…: $restore_type"
    
    # ë°±ì—… íŒŒì¼/ë””ë ‰í† ë¦¬ ì°¾ê¸°
    local backup_path=""
    local temp_extract_dir=""
    
    # ë¡œì»¬ì—ì„œ ë°±ì—… ì°¾ê¸°
    if [[ -d "$BACKUP_DIR/$backup_name" ]]; then
        backup_path="$BACKUP_DIR/$backup_name"
    elif [[ -f "$BACKUP_DIR/$backup_name" ]]; then
        backup_path="$BACKUP_DIR/$backup_name"
    elif [[ -f "$BACKUP_DIR/${backup_name}.tar.gz" ]]; then
        backup_path="$BACKUP_DIR/${backup_name}.tar.gz"
    elif [[ -f "$BACKUP_DIR/${backup_name}.encrypted.tar.gz" ]]; then
        backup_path="$BACKUP_DIR/${backup_name}.encrypted.tar.gz"
    else
        # S3ì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
        if [[ "$S3_ENABLED" == "true" ]] && command -v aws >/dev/null 2>&1; then
            log_info "S3ì—ì„œ ë°±ì—… ë‹¤ìš´ë¡œë“œ ì¤‘"
            
            export AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY"
            export AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY"
            export AWS_DEFAULT_REGION="$S3_REGION"
            
            local temp_backup="/tmp/$backup_name"
            aws s3 cp "s3://$S3_BUCKET/stockpilot-backups/$backup_name" "$temp_backup" || {
                log_error "S3ì—ì„œ ë°±ì—… ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"
                return 1
            }
            backup_path="$temp_backup"
        else
            log_error "ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $backup_name"
            return 1
        fi
    fi
    
    # ì••ì¶•/ì•”í˜¸í™”ëœ ë°±ì—… í•´ì œ
    if [[ -f "$backup_path" ]]; then
        temp_extract_dir="/tmp/restore_$backup_name_$(date +%s)"
        mkdir -p "$temp_extract_dir"
        
        if [[ "$backup_path" =~ \.encrypted\. ]]; then
            # ì•”í˜¸í™”ëœ ë°±ì—… ë³µí˜¸í™”
            if [[ -z "$ENCRYPTION_KEY" ]]; then
                log_error "ì•”í˜¸í™”ëœ ë°±ì—…ì´ì§€ë§Œ ë³µí˜¸í™” í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤"
                return 1
            fi
            
            log_info "ì•”í˜¸í™”ëœ ë°±ì—… ë³µí˜¸í™” ì¤‘"
            openssl enc -aes-256-cbc -d -salt -pbkdf2 -pass pass:"$ENCRYPTION_KEY" -in "$backup_path" | \
            tar -xzf - -C "$temp_extract_dir" || {
                log_error "ë°±ì—… ë³µí˜¸í™” ì‹¤íŒ¨"
                return 1
            }
            
        elif [[ "$backup_path" =~ \.tar\.gz$ ]]; then
            # ì••ì¶•ëœ ë°±ì—… í•´ì œ
            log_info "ì••ì¶•ëœ ë°±ì—… í•´ì œ ì¤‘"
            tar -xzf "$backup_path" -C "$temp_extract_dir" || {
                log_error "ë°±ì—… ì••ì¶• í•´ì œ ì‹¤íŒ¨"
                return 1
            }
        fi
        
        # í•´ì œëœ ë””ë ‰í† ë¦¬ë¥¼ backup_pathë¡œ ì„¤ì •
        local extracted_dir=$(find "$temp_extract_dir" -maxdepth 1 -type d -name "stockpilot_*" | head -1)
        if [[ -n "$extracted_dir" ]]; then
            backup_path="$extracted_dir"
        else
            backup_path="$temp_extract_dir"
        fi
    fi
    
    # ë³µêµ¬ í™•ì¸
    if [[ "$FORCE_RESTORE" != "true" ]]; then
        echo -n "ë°±ì—…ì„ ë³µêµ¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ê¸°ì¡´ ë°ì´í„°ê°€ ë®ì–´ì“°ì—¬ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (y/N): "
        read -r confirmation
        if [[ "$confirmation" != "y" && "$confirmation" != "Y" ]]; then
            log_info "ë³µêµ¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤"
            [[ -n "$temp_extract_dir" ]] && rm -rf "$temp_extract_dir"
            return 0
        fi
    fi
    
    # ë³µêµ¬ íƒ€ì…ì— ë”°ë¥¸ ì‹¤í–‰
    case $restore_type in
        all|db)
            restore_database "$backup_path"
            [[ "$restore_type" == "db" ]] && break
            ;;&
        all|files)
            restore_files "$backup_path"
            [[ "$restore_type" == "files" ]] && break
            ;;&
        all|config)
            restore_config "$backup_path"
            [[ "$restore_type" == "config" ]] && break
            ;;
        *)
            log_error "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë³µêµ¬ íƒ€ì…: $restore_type"
            [[ -n "$temp_extract_dir" ]] && rm -rf "$temp_extract_dir"
            return 1
            ;;
    esac
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    [[ -n "$temp_extract_dir" ]] && rm -rf "$temp_extract_dir"
    
    log_success "ë°±ì—… ë³µêµ¬ ì™„ë£Œ"
}

# ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
restore_database() {
    local backup_path="$1"
    
    if [[ -z "${DATABASE_URL:-}" ]]; then
        log_warning "DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤"
        return
    fi
    
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì‹œì‘"
    
    # ë°±ì—… íŒŒì¼ ì°¾ê¸°
    local db_backup_file=""
    if [[ -f "$backup_path/database.sql.gz" ]]; then
        db_backup_file="$backup_path/database.sql.gz"
    elif [[ -f "$backup_path/database.sql" ]]; then
        db_backup_file="$backup_path/database.sql"
    elif [[ -f "$backup_path/database.sql.backup.gz" ]]; then
        db_backup_file="$backup_path/database.sql.backup.gz"
    elif [[ -f "$backup_path/database.sql.backup" ]]; then
        db_backup_file="$backup_path/database.sql.backup"
    else
        log_error "ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        return 1
    fi
    
    log_info "ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… íŒŒì¼: $db_backup_file"
    
    # PostgreSQL ë³µêµ¬
    if [[ "$DATABASE_URL" =~ ^postgresql:// ]]; then
        log_info "PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬"
        
        if [[ "$db_backup_file" =~ \.gz$ ]]; then
            # ì••ì¶•ëœ ë°±ì—… ë³µêµ¬
            if [[ "$db_backup_file" =~ \.backup\.gz$ ]]; then
                # custom í˜•ì‹ ë³µêµ¬
                gunzip -c "$db_backup_file" | pg_restore -d "$DATABASE_URL" --clean --if-exists --verbose || {
                    log_error "PostgreSQL ë³µêµ¬ ì‹¤íŒ¨"
                    return 1
                }
            else
                # plain í˜•ì‹ ë³µêµ¬
                gunzip -c "$db_backup_file" | psql "$DATABASE_URL" || {
                    log_error "PostgreSQL ë³µêµ¬ ì‹¤íŒ¨"
                    return 1
                }
            fi
        else
            # ë¹„ì••ì¶• ë°±ì—… ë³µêµ¬
            if [[ "$db_backup_file" =~ \.backup$ ]]; then
                # custom í˜•ì‹ ë³µêµ¬
                pg_restore -d "$DATABASE_URL" --clean --if-exists --verbose "$db_backup_file" || {
                    log_error "PostgreSQL ë³µêµ¬ ì‹¤íŒ¨"
                    return 1
                }
            else
                # plain í˜•ì‹ ë³µêµ¬
                psql "$DATABASE_URL" < "$db_backup_file" || {
                    log_error "PostgreSQL ë³µêµ¬ ì‹¤íŒ¨"
                    return 1
                }
            fi
        fi
    else
        log_error "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì…ë‹ˆë‹¤"
        return 1
    fi
    
    log_success "ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì™„ë£Œ"
}

# íŒŒì¼ ë³µêµ¬
restore_files() {
    local backup_path="$1"
    
    log_info "ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë³µêµ¬ ì‹œì‘"
    
    # ë°±ì—… íŒŒì¼ ì°¾ê¸°
    local files_backup_file=""
    if [[ -f "$backup_path/application_files.tar.gz" ]]; then
        files_backup_file="$backup_path/application_files.tar.gz"
    elif [[ -f "$backup_path/application_files.tar" ]]; then
        files_backup_file="$backup_path/application_files.tar"
    else
        log_error "íŒŒì¼ ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        return 1
    fi
    
    log_info "íŒŒì¼ ë°±ì—…: $files_backup_file"
    
    cd "$PROJECT_ROOT"
    
    # ê¸°ì¡´ íŒŒì¼ ë°±ì—… (ì•ˆì „ì¥ì¹˜)
    local backup_timestamp=$(date '+%Y%m%d_%H%M%S')
    local safety_backup_dir="/tmp/stockpilot_restore_backup_$backup_timestamp"
    mkdir -p "$safety_backup_dir"
    
    log_info "ì•ˆì „ì„ ìœ„í•´ ê¸°ì¡´ íŒŒì¼ ì„ì‹œ ë°±ì—…: $safety_backup_dir"
    cp -r backend frontend scripts docs "$safety_backup_dir/" 2>/dev/null || true
    
    # íŒŒì¼ ë³µêµ¬
    if [[ "$files_backup_file" =~ \.gz$ ]]; then
        tar -xzf "$files_backup_file" || {
            log_error "íŒŒì¼ ë³µêµ¬ ì‹¤íŒ¨"
            return 1
        }
    else
        tar -xf "$files_backup_file" || {
            log_error "íŒŒì¼ ë³µêµ¬ ì‹¤íŒ¨"
            return 1
        }
    fi
    
    log_success "ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë³µêµ¬ ì™„ë£Œ"
    log_info "ê¸°ì¡´ íŒŒì¼ ë°±ì—… ìœ„ì¹˜: $safety_backup_dir (ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œí•˜ì„¸ìš”)"
}

# ì„¤ì • ë³µêµ¬
restore_config() {
    local backup_path="$1"
    
    log_info "ì„¤ì • íŒŒì¼ ë³µêµ¬ ì‹œì‘"
    
    local config_backup_dir="$backup_path/config"
    
    if [[ ! -d "$config_backup_dir" ]]; then
        log_error "ì„¤ì • ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        return 1
    fi
    
    # ì„¤ì • íŒŒì¼ë“¤ ë³µêµ¬
    for config_file in "$config_backup_dir"/*; do
        local filename=$(basename "$config_file")
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê±´ë„ˆë›°ê¸°
        [[ "$filename" == "metadata.txt" ]] && continue
        
        local target_path=""
        
        # ì‹œìŠ¤í…œ íŒŒì¼ì¸ì§€ í™•ì¸
        if [[ "$filename" == "stockpilot.service" ]]; then
            target_path="/etc/systemd/system/$filename"
            log_info "ì‹œìŠ¤í…œ ì„¤ì • íŒŒì¼ ë³µêµ¬: $target_path"
            sudo cp "$config_file" "$target_path"
            sudo systemctl daemon-reload
        else
            target_path="$PROJECT_ROOT/$filename"
            log_info "ì„¤ì • íŒŒì¼ ë³µêµ¬: $target_path"
            cp "$config_file" "$target_path"
        fi
    done
    
    log_success "ì„¤ì • íŒŒì¼ ë³µêµ¬ ì™„ë£Œ"
}

# ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
cleanup_old_backups() {
    local retention_days="${CLEANUP_DAYS:-$RETENTION_DAYS}"
    
    log_info "ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ ì‹œì‘ (ë³´ê´€ê¸°ê°„: ${retention_days}ì¼)"
    
    if [[ ! -d "$BACKUP_DIR" ]]; then
        log_warning "ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: $BACKUP_DIR"
        return
    fi
    
    local deleted_count=0
    
    # ë¡œì»¬ ë°±ì—… ì •ë¦¬
    find "$BACKUP_DIR" -name "stockpilot_*" -type d -mtime +$retention_days -exec rm -rf {} + 2>/dev/null || true
    find "$BACKUP_DIR" -name "stockpilot_*.tar.gz" -type f -mtime +$retention_days -exec rm -f {} + 2>/dev/null || true
    find "$BACKUP_DIR" -name "stockpilot_*.encrypted.tar.gz" -type f -mtime +$retention_days -exec rm -f {} + 2>/dev/null || true
    
    log_success "ë¡œì»¬ ë°±ì—… ì •ë¦¬ ì™„ë£Œ"
    
    # S3 ë°±ì—… ì •ë¦¬ (ì„ íƒì‚¬í•­)
    if [[ "$S3_ENABLED" == "true" ]] && command -v aws >/dev/null 2>&1; then
        log_info "S3 ë°±ì—… ì •ë¦¬ ì¤‘"
        
        export AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY"
        export AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY"
        export AWS_DEFAULT_REGION="$S3_REGION"
        
        # 30ì¼ ì´ìƒ ëœ S3 ë°±ì—… ì‚­ì œ
        local cutoff_date=$(date -u -d "$retention_days days ago" +"%Y-%m-%d" 2>/dev/null || date -u -v-${retention_days}d +"%Y-%m-%d" 2>/dev/null)
        
        aws s3api list-objects-v2 --bucket "$S3_BUCKET" --prefix "stockpilot-backups/" --query "Contents[?LastModified<'$cutoff_date'].Key" --output text | \
        while read -r key; do
            if [[ -n "$key" ]]; then
                aws s3 rm "s3://$S3_BUCKET/$key"
                ((deleted_count++))
            fi
        done
        
        log_success "S3 ë°±ì—… ì •ë¦¬ ì™„ë£Œ ($deleted_count ê°œ íŒŒì¼ ì‚­ì œ)"
    fi
    
    log_success "ë°±ì—… ì •ë¦¬ ì™„ë£Œ"
}

# ë°±ì—… í…ŒìŠ¤íŠ¸
test_backup() {
    log_info "ë°±ì—… í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì‹¤ì œ ë°±ì—…ì€ ìƒì„±ë˜ì§€ ì•ŠìŒ)"
    
    # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
    local missing_tools=()
    
    command -v pg_dump >/dev/null 2>&1 || missing_tools+=("postgresql-client")
    command -v tar >/dev/null 2>&1 || missing_tools+=("tar")
    command -v gzip >/dev/null 2>&1 || missing_tools+=("gzip")
    
    if [[ "$ENCRYPT_BACKUPS" == "true" ]]; then
        command -v openssl >/dev/null 2>&1 || missing_tools+=("openssl")
    fi
    
    if [[ "$S3_ENABLED" == "true" ]]; then
        command -v aws >/dev/null 2>&1 || missing_tools+=("awscli")
    fi
    
    if [[ ${#missing_tools[@]} -gt 0 ]]; then
        log_error "ë‹¤ìŒ ë„êµ¬ë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤:"
        for tool in "${missing_tools[@]}"; do
            echo "  - $tool"
        done
        return 1
    fi
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
    if [[ -n "${DATABASE_URL:-}" ]]; then
        log_info "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"
        if pg_isready -d "$DATABASE_URL" >/dev/null 2>&1; then
            log_success "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ"
        else
            log_error "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
            return 1
        fi
    fi
    
    # S3 ì—°ê²° í…ŒìŠ¤íŠ¸
    if [[ "$S3_ENABLED" == "true" ]]; then
        log_info "S3 ì—°ê²° í…ŒìŠ¤íŠ¸"
        
        export AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY"
        export AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY"
        export AWS_DEFAULT_REGION="$S3_REGION"
        
        if aws s3 ls "s3://$S3_BUCKET" >/dev/null 2>&1; then
            log_success "S3 ì—°ê²° ì„±ê³µ"
        else
            log_error "S3 ì—°ê²° ì‹¤íŒ¨"
            return 1
        fi
    fi
    
    # ë°±ì—… ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ í…ŒìŠ¤íŠ¸
    if mkdir -p "$BACKUP_DIR" 2>/dev/null && touch "$BACKUP_DIR/.test" 2>/dev/null; then
        rm -f "$BACKUP_DIR/.test"
        log_success "ë°±ì—… ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ í™•ì¸"
    else
        log_error "ë°±ì—… ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ ì—†ìŒ: $BACKUP_DIR"
        return 1
    fi
    
    log_success "ëª¨ë“  ë°±ì—… í…ŒìŠ¤íŠ¸ í†µê³¼"
}

# ë©”ì¸ í•¨ìˆ˜
main() {
    # ë§¤ê°œë³€ìˆ˜ íŒŒì‹±
    COMMAND=""
    BACKUP_TYPE="all"
    RESTORE_TYPE="all"
    BACKUP_NAME=""
    CONFIG_FILE=""
    VERBOSE=false
    FORCE_RESTORE=false
    CLEANUP_DAYS=""
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            backup|restore|list|cleanup|test)
                COMMAND="$1"
                shift
                ;;
            --type)
                if [[ "$COMMAND" == "restore" ]]; then
                    RESTORE_TYPE="$2"
                else
                    BACKUP_TYPE="$2"
                fi
                shift 2
                ;;
            --backup)
                BACKUP_NAME="$2"
                shift 2
                ;;
            --name)
                BACKUP_NAME="$2"
                shift 2
                ;;
            --dir)
                BACKUP_DIR="$2"
                shift 2
                ;;
            --config)
                CONFIG_FILE="$2"
                shift 2
                ;;
            --days)
                CLEANUP_DAYS="$2"
                shift 2
                ;;
            --compress)
                COMPRESS_BACKUPS=true
                shift
                ;;
            --encrypt)
                ENCRYPT_BACKUPS=true
                shift
                ;;
            --s3)
                S3_ENABLED=true
                shift
                ;;
            --force)
                FORCE_RESTORE=true
                shift
                ;;
            --verbose)
                VERBOSE=true
                shift
                ;;
            --help)
                show_help
                exit 0
                ;;
            *)
                log_error "ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    # ëª…ë ¹ì–´ í™•ì¸
    if [[ -z "$COMMAND" ]]; then
        log_error "ëª…ë ¹ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤"
        show_help
        exit 1
    fi
    
    # ë°°ë„ˆ ì¶œë ¥
    print_banner
    
    # ì„¤ì • ë¡œë“œ
    load_config
    
    # ìƒì„¸ ë¡œê·¸ ì„¤ì •
    if [[ "$VERBOSE" == "true" ]]; then
        set -x
    fi
    
    # ëª…ë ¹ ì‹¤í–‰
    case $COMMAND in
        backup)
            run_backup
            ;;
        restore)
            if [[ -z "$BACKUP_NAME" ]]; then
                log_error "ë³µêµ¬í•  ë°±ì—… ì´ë¦„ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤ (--backup NAME)"
                exit 1
            fi
            restore_backup "$BACKUP_NAME"
            ;;
        list)
            list_backups
            ;;
        cleanup)
            cleanup_old_backups
            ;;
        test)
            test_backup
            ;;
        *)
            log_error "ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª…ë ¹: $COMMAND"
            exit 1
            ;;
    esac
    
    log_success "ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰"
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi